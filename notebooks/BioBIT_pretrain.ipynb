{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IVN-RIN/bio-med-BIT/blob/main/notebooks/BioBIT_pretrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BioBIT Experiment For <u>Pre-Training</u>**\n",
        "\n",
        "*Tommaso Buonocore, University of Pavia, 2022*<br>\n",
        "*Claudio Crema, IRCCS Centro San Giovanni di Dio Fatebenefratelli, 2022*\n",
        "\n",
        "*Last edited: 16/11/2022*"
      ],
      "metadata": {
        "id": "A01U9IQdNGBi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5YJ41wlmg7N"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Short string describing the current run"
      ],
      "metadata": {
        "id": "C4Pp_wQ3NK0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_name = \"Pretraining-MedvX\""
      ],
      "metadata": {
        "id": "-Vm6QPViNMlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5an4xejDV-C"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5duRggBRZKvP"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install transformers==4.23.1 install tokenizers install datasets\n",
        "\n",
        "# Google Colab only\n",
        "from google.colab import runtime, drive\n",
        "\n",
        "#General\n",
        "import torch\n",
        "from itertools import chain\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "from io import StringIO\n",
        "import time\n",
        "\n",
        "# HuggingFace Transformers\n",
        "from transformers import BertTokenizerFast, BertForMaskedLM, AutoModelForMaskedLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "from datasets import load_from_disk, load_dataset\n",
        "\n",
        "# Set device to GPU Cuda if available \n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Session Info"
      ],
      "metadata": {
        "id": "eloncrpiNsx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session_info = json.loads(os.popen(\"curl curl ipinfo.io\").read())\n",
        "if device=='cuda':\n",
        "  gpu_info = pd.read_csv(StringIO(os.popen(\"nvidia-smi --query-gpu=gpu_name,memory.total --format=csv\").read()),names=[\"name\",\"memory\"],header=0)\n",
        "  session_info[f'gpus'] = [{'name': row[\"name\"], 'memory': row[\"memory\"]} for index, row in gpu_info.iterrows()] \n",
        "else: \n",
        "  session_info[f'gpus'] = []\n",
        "session_info['time_start'] = time.strftime(\"%H:%M:%S\", time.localtime())\n",
        "session_info['experiment_name'] = experiment_name\n",
        "session_info"
      ],
      "metadata": {
        "id": "wB28y5xMNuTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we are dealing with large files, we are going to realy solely upon Google Drive for both inputs and outputs."
      ],
      "metadata": {
        "id": "61_bps0R7FpE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqZr00S9LDUd"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btF3CUe4lMF4"
      },
      "source": [
        "## Global Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kf6rEv5nT6cD"
      },
      "outputs": [],
      "source": [
        "original_model = \"/content/gdrive/MyDrive/Colab Environments/biobert_models/bio-full\"\n",
        "#original_model = \"dbmdz/bert-base-italian-xxl-cased\"\n",
        "output_model_path = \"./med-orig\"\n",
        "#dataset arrow version\n",
        "corpus_path = '/content/gdrive/MyDrive/Colab Environments/PRETRAIN/med-whole-clean'\n",
        "#collection of txt corpora\n",
        "corpus_paths_common_root = '/content/gdrive/MyDrive/Colab Environments/PRETRAIN/'\n",
        "corpus_paths_txt = ['med-whole-clean/med-whole-clean.txt',\n",
        "                    # 'medicitalia-dump/medicitalia_dump_blog.txt','medicitalia-dump/medicitalia_dump_minforma.txt','medicitalia-dump/medicitalia_dump_salute.txt',\n",
        "                    # 'mypersonaltrainer-dump/dump_benessere.txt','mypersonaltrainer-dump/dump_biologia.txt','mypersonaltrainer-dump/dump_farmaci.txt','mypersonaltrainer-dump/dump_farmaci-malattie.txt',\n",
        "                    # 'mypersonaltrainer-dump/dump_farmacologia.txt','mypersonaltrainer-dump/dump_fisiologia.txt','mypersonaltrainer-dump/dump_rimedi.txt','mypersonaltrainer-dump/dump_salute.txt',\n",
        "                    # 'mypersonaltrainer-dump/dump_salute-benessere.txt','mypersonaltrainer-dump/dump_traumatologia-ortopedia.txt',\n",
        "                    # 'mypersonaltrainer-dump/dump_rimedi.txt','mypersonaltrainer-dump/dump_salute.txt','dica33_dump.txt'\n",
        "                    ]\n",
        "\n",
        "# mlm task\n",
        "mlm_probability = 0.15\n",
        "pad_to_multiple_of_8 = True\n",
        "\n",
        "# experience replay params\n",
        "replay_freq = 100 \n",
        "old_corpus_path = '/content/gdrive/MyDrive/Colab Environments/PRETRAIN/bio-small'\n",
        "\n",
        "# mixout params\n",
        "mixout_prob = 0.9\n",
        "\n",
        "# optimizer params\n",
        "learning_rate = 3e-5\n",
        "layerwise_learning_rate_decay = 0.95\n",
        "weight_decay = 0.01\n",
        "adam_epsilon = 1e-6\n",
        "use_bertadam = False\n",
        "\n",
        "# scheduler params\n",
        "epochs = 10\n",
        "batch_size = 16\n",
        "warmup_ratio = 0.02 #the number of warmup steps is 2% of the total training steps\n",
        "\n",
        "# switch on/off CF mitigation techniques here\n",
        "cf_is_on = {\n",
        "    \"mixout\":True,\n",
        "    \"experience_replay\":False,\n",
        "    \"llrd\":True,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-kkz81OY6xH"
      },
      "source": [
        "# Tokenizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErVCd16lm8qZ"
      },
      "source": [
        "Get Model and Tokenizer from pretrained checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4keFBUjQFOD1"
      },
      "outputs": [],
      "source": [
        "#Use BertForPreTraining for ML and NSP and BertForMaskedLM to drop the NSP task as in Roberta\n",
        "tokenizer = BertTokenizerFast.from_pretrained(original_model, max_len=512)\n",
        "model = BertForMaskedLM.from_pretrained(original_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBtUHRMliOLM"
      },
      "source": [
        "##3. Build the training Dataset\n",
        "\n",
        "We'll build our dataset by applying our tokenizer to our text file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56TbIw8yWsx9"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset_for_mlm(raw_dataset,tokenizer, batched=True, load_from_cache_file = False):\n",
        "  \"\"\"\n",
        "  We tokenize every text, then concatenate them together before splitting them in smaller parts.\n",
        "  We use `return_special_tokens_mask=True` because DataCollatorForLanguageModeling (see below) is more efficient when it receives the `special_tokens_mask`.\n",
        "  \"\"\"\n",
        "  column_names = raw_dataset[\"train\"].column_names\n",
        "  text_column_name = \"text\" if \"text\" in column_names else column_names[0]\n",
        "  max_seq_length = tokenizer.model_max_length\n",
        "\n",
        "  def tokenize_function(examples):\n",
        "    return tokenizer(examples[text_column_name], return_special_tokens_mask=True)\n",
        "\n",
        "  tokenized_datasets = raw_dataset.map(\n",
        "      tokenize_function,\n",
        "      batched=batched,\n",
        "      remove_columns=column_names,\n",
        "      load_from_cache_file=load_from_cache_file,\n",
        "      desc=\"Running tokenizer on every text in dataset\",\n",
        "  )\n",
        "\n",
        "  def group_texts(examples):\n",
        "    # Concatenate all texts.\n",
        "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "    if total_length >= max_seq_length:\n",
        "        total_length = (total_length // max_seq_length) * max_seq_length\n",
        "    # Split by chunks of max_len.\n",
        "    result = {\n",
        "        k: [t[i : i + max_seq_length] for i in range(0, total_length, max_seq_length)]\n",
        "        for k, t in concatenated_examples.items()\n",
        "    }\n",
        "    return result\n",
        "\n",
        "  tokenized_datasets = tokenized_datasets.map(\n",
        "    group_texts,\n",
        "    batched=batched,\n",
        "    load_from_cache_file=load_from_cache_file,\n",
        "    desc=f\"Grouping texts in chunks of {max_seq_length}\",\n",
        "  )\n",
        "\n",
        "  return tokenized_datasets[\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2cQGwaHWldk"
      },
      "outputs": [],
      "source": [
        "#OPTION 1: dataset stored as arrow file\n",
        "# raw_dataset = load_from_disk(corpus_path)\n",
        "# train_dataset = prepare_dataset_for_mlm(raw_dataset,tokenizer)\n",
        "\n",
        "#OPTION 2: dataset(s) stored as txt file(s)\n",
        "raw_dataset = load_dataset(\"text\", data_files={\"train\": [corpus_paths_common_root+s for s in corpus_paths_txt]})\n",
        "train_dataset = prepare_dataset_for_mlm(raw_dataset,tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtCQJ5eId0wi"
      },
      "source": [
        "# Catastrophic Forgetting Mitigation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3nTXSQvU5d1"
      },
      "source": [
        "## **Mixout**\n",
        "\n",
        "Described in [Lee et al., 2020](https://arxiv.org/pdf/1909.11299.pdf), this technique regularizes learning to minimize the deviation from the target parameters.\n",
        "\n",
        "<img src=\"https://github.com/bloodwass/mixout/raw/master/imgs/mixout.png\"/>\n",
        "\n",
        "Suppose that u and w are a target model parameter and a current model parameter, respectively. \n",
        "\n",
        "\n",
        "*   a) We first memorize the parameters of the vanilla network at u. \n",
        "*   b) In the dropout network, we randomly choose an input neuron to be dropped(a dotted neuron) with a probability of p. That is, all outgoing parameters from the dropped neuron are eliminated (dotted connections). \n",
        "*   c) In the mixout(u) network, the eliminated parameters in (b) are replaced by the corresponding parameters in (a). \n",
        "\n",
        "In other words, the mixout(u) network at w is the mixture of the vanilla network at u and the dropout network at w with a probability of p."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dk0T_x8VrHxc"
      },
      "outputs": [],
      "source": [
        "##++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "## Created by: Cheolhyoung Lee\n",
        "## Department of Mathematical Sciences, KAIST\n",
        "## Email: cheolhyoung.lee@kaist.ac.kr\n",
        "## Implementation of mixout from https://arxiv.org/abs/1909.11299\n",
        "## \"Mixout: Effective Regularization to Finetune Large-scale Pretrained Language Models\"\n",
        "##++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "import math\n",
        "import torch\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Parameter\n",
        "from torch.autograd.function import InplaceFunction\n",
        "from typing import Optional\n",
        "from collections import OrderedDict\n",
        "\n",
        "class Mixout(InplaceFunction):\n",
        "    # target: a weight tensor mixes with a input tensor\n",
        "    # A forward method returns \n",
        "    # [(1 - Bernoulli(1 - p) mask) * target + (Bernoulli(1 - p) mask) * input - p * target]/(1 - p) \n",
        "    # where p is a mix probability of mixout.\n",
        "    # A backward returns the gradient of the forward method.\n",
        "    # Dropout is equivalent to the case of target=None. \n",
        "    # I modified the code of dropout in PyTorch. \n",
        "    @staticmethod\n",
        "    def _make_noise(input:torch.Tensor) -> torch.Tensor:\n",
        "        return input.new().resize_as_(input)\n",
        "\n",
        "    @classmethod\n",
        "    def forward(cls, \n",
        "                ctx, \n",
        "                input:torch.Tensor, \n",
        "                target:Optional[\"OrderedDict[str, torch.Tensor]\"]=None, \n",
        "                p:float=0.0, \n",
        "                training:bool=False, \n",
        "                inplace:bool=False) -> torch.Tensor:\n",
        "\n",
        "        if p < 0 or p > 1:\n",
        "            raise ValueError(f\"A mix probability of mixout has to be between 0 and 1,  but got {p}\")\n",
        "\n",
        "        if target is not None and input.size() != target.size():\n",
        "            raise ValueError(f\"A target tensor size must match with a input tensor size {input.size()}, but got {target.size()}\")\n",
        "        \n",
        "        ctx.p = p    \n",
        "        ctx.training = training\n",
        "        \n",
        "        if target is None:\n",
        "            target = cls._make_noise(input)\n",
        "            target.fill_(0)\n",
        "        target = target.to(input.device)\n",
        "\n",
        "        if inplace:\n",
        "            ctx.mark_dirty(input)\n",
        "            output = input\n",
        "        else:\n",
        "            output = input.clone()\n",
        "        \n",
        "        if ctx.p == 0 or not ctx.training:\n",
        "            return output\n",
        "        \n",
        "        ctx.noise = cls._make_noise(input)\n",
        "        if len(ctx.noise.size()) == 1:\n",
        "            ctx.noise.bernoulli_(1 - ctx.p)\n",
        "        else:\n",
        "            ctx.noise[0].bernoulli_(1 - ctx.p)\n",
        "            ctx.noise = ctx.noise[0].repeat(input.size()[0], *([1] * (len(input.size())-1)))\n",
        "        ctx.noise.expand_as(input)\n",
        "        \n",
        "        if ctx.p == 1:\n",
        "            output = target.clone()\n",
        "        else:\n",
        "            output = ((1 - ctx.noise) * target + ctx.noise * output - ctx.p * target) / (1 - ctx.p)\n",
        "        \n",
        "        return output\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output:torch.Tensor) -> Optional[torch.Tensor]:\n",
        "        if ctx.p > 0 and ctx.training:\n",
        "            return grad_output * ctx.noise, None, None, None, None\n",
        "        else:\n",
        "            return grad_output, None, None, None, None\n",
        "\n",
        "\n",
        "def mixout(input:torch.Tensor, \n",
        "           target:Optional[\"OrderedDict[str, torch.Tensor]\"]=None, \n",
        "           p:float=0.0, \n",
        "           training:bool=False, \n",
        "           inplace:bool=False) -> torch.Tensor:\n",
        "\n",
        "    return Mixout.apply(input, target, p, training, inplace)\n",
        "\n",
        "class MixLinear(torch.nn.Module):\n",
        "    __constants__ = ['bias', 'in_features', 'out_features']\n",
        "    # If target is None, nn.Sequential(nn.Linear(m, n), MixLinear(m', n', p)) \n",
        "    # is equivalent to nn.Sequential(nn.Linear(m, n), nn.Dropout(p), nn.Linear(m', n')).\n",
        "    # If you want to change a dropout layer to a mixout layer, \n",
        "    # you should replace nn.Linear right after nn.Dropout(p) with Mixout(p) \n",
        "    def __init__(self, \n",
        "                in_features:int, \n",
        "                out_features:int, \n",
        "                bias:bool=True, \n",
        "                target:Optional[\"OrderedDict[str, torch.Tensor]\"]=None, \n",
        "                p:float=0.0) -> None:\n",
        "\n",
        "        super(MixLinear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.Tensor(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "        self.reset_parameters()\n",
        "        self.target = target\n",
        "        self.p = p\n",
        "\n",
        "        if self.p < 0 or self.p > 1:\n",
        "            raise ValueError(f\"A mix probability of mixout has to be between 0 and 1,  but got {self.p}\")\n",
        "    \n",
        "    def reset_parameters(self) -> None:\n",
        "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "        if self.bias is not None:\n",
        "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
        "            bound = 1 / math.sqrt(fan_in)\n",
        "            init.uniform_(self.bias, -bound, bound)\n",
        "            \n",
        "    def forward(self, input:torch.Tensor) -> torch.Tensor:\n",
        "        return F.linear(input, mixout(self.weight, self.target, \n",
        "                                      self.p, self.training), self.bias)\n",
        "\n",
        "    def extra_repr(self):\n",
        "        type_ = 'drop' if self.target is None else 'mix'\n",
        "        type_ += \"out\" \n",
        "        return f'{type_}={self.p}, in_features={self.in_features}, out_features={self.out_features}, bias={self.bias is not None}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTqwLSg3U701"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from copy import deepcopy\n",
        "\n",
        "def replace_layer_for_mixout(module: nn.Module, mixout_prob: float) -> nn.Module:\n",
        "        '''\n",
        "        Replaces a single layer with the correct layer for use with Mixout.\n",
        "        If module is nn.Dropout, replaces it with a Dropout where p = 0.\n",
        "        If module is nn.Linear, replaces it with a MixLinear where p(mixout) = mixout_prob.\n",
        "        In all other cases, returns the module unchanged.\n",
        "        \n",
        "            params:\n",
        "                module (nn.Module)    : a module to replace for Mixout\n",
        "                mixout_prob (float)   : the desired Mixout probability\n",
        "            \n",
        "            returns:\n",
        "                module (nn.Module)    : the module set up for use with Mixout\n",
        "        '''\n",
        "        if isinstance(module, nn.Dropout):\n",
        "            return nn.Dropout(0)\n",
        "        elif isinstance(module, nn.Linear):\n",
        "            target_state_dict   = deepcopy(module.state_dict())\n",
        "            bias                = True if module.bias is not None else False\n",
        "            new_module          = MixLinear(\n",
        "                                    module.in_features,\n",
        "                                    module.out_features,\n",
        "                                    bias,\n",
        "                                    target_state_dict['weight'],\n",
        "                                    mixout_prob\n",
        "                                )\n",
        "            new_module.load_state_dict(target_state_dict)\n",
        "            return new_module\n",
        "        else:\n",
        "            return module\n",
        "\n",
        "def recursive_setattr(obj: 'any', attr: str, value: 'any') -> None:\n",
        "    '''\n",
        "    Recursively sets attributes for objects with children.\n",
        "    \n",
        "        params:\n",
        "            obj (any)   : the object with children whose attribute is to be set\n",
        "            attr (str)  : the (nested) attribute of the object, with levels indicated by '.'\n",
        "                          for instance attr='attr1.attr2' sets the attr2 of obj.attr1 to\n",
        "                          the passed value\n",
        "            value (any) : what to set the attribute to\n",
        "    '''\n",
        "    attr = attr.split('.', 1)\n",
        "    if len(attr) == 1:\n",
        "        setattr(obj, attr[0], value)\n",
        "    else:\n",
        "        recursive_setattr(getattr(obj, attr[0]), attr[1], value)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if cf_is_on[\"mixout\"]:\n",
        "  print('Adding mixout...')\n",
        "  print(model)\n",
        "\n",
        "  # use tuple to avoid OrderedDict warning\n",
        "  for name, module in tuple(model.named_modules()):\n",
        "      if name:\n",
        "          recursive_setattr(model, name, replace_layer_for_mixout(module, mixout_prob=mixout_prob))"
      ],
      "metadata": {
        "id": "swUNiN_L4bzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhirgeRTT78M"
      },
      "source": [
        "## **Experience Replay**\n",
        "\n",
        "At a certain interval (1% replay rate) throughout the learning period, uniformly sample from stored examples in the memory and perform gradient updates of the encoder-decoder network based on the retrieved examples. It helps mitigate catestophic forgetting.\n",
        "\n",
        "<img src=\"https://github.com/h3lio5/episodic-lifelong-learning/raw/master/images/train_infer_new.png\"/>\n",
        "\n",
        "In the [original paper](https://github.com/h3lio5/episodic-lifelong-learning/blob/master/main.py) this process is handled directly inside the training process. The \"naive\" version might be to inject a random sampled batch of old examples every N batches (according to the replay rate) directly into the training dataset.\n",
        "\n",
        "It is not yet clear to me what are the implications of using the naive version instead of the original one. Maybe the repetition of the same examples over different epochs vs sampling different old examples every time?\n",
        "\n",
        "trainer: https://github.com/huggingface/transformers/blob/v4.23.1/src/transformers/trainer.py#L209\n",
        "\n",
        "The only way to implement experience replay in the Transformer's `Trainer` is to extend the `Trainer` class modifying the `inner_training_loop` method. In particular, we customize the inner loop to perform an additional forward+backward training step on a random sampled batch from old pretraining data every `replay_freq` steps. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "We0mkzJhvkcH"
      },
      "outputs": [],
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2020-present the HuggingFace Inc. team.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\"\n",
        "The Trainer class, to easily train a ðŸ¤— Transformers from scratch or finetune it on a new task.\n",
        "\"\"\"\n",
        "\n",
        "import contextlib\n",
        "import functools\n",
        "import glob\n",
        "import inspect\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import shutil\n",
        "import sys\n",
        "import time\n",
        "import warnings\n",
        "from collections.abc import Mapping\n",
        "from pathlib import Path\n",
        "from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Union\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "# Integrations must be imported before ML frameworks:\n",
        "from transformers.integrations import (  # isort: split\n",
        "    default_hp_search_backend,\n",
        "    get_reporting_integration_callbacks,\n",
        "    hp_params,\n",
        "    is_fairscale_available,\n",
        "    is_optuna_available,\n",
        "    is_ray_tune_available,\n",
        "    is_sigopt_available,\n",
        "    is_wandb_available,\n",
        "    run_hp_search_optuna,\n",
        "    run_hp_search_ray,\n",
        "    run_hp_search_sigopt,\n",
        "    run_hp_search_wandb,\n",
        ")\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "from packaging import version\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "\n",
        "from huggingface_hub import Repository\n",
        "\n",
        "from transformers import __version__\n",
        "from transformers.configuration_utils import PretrainedConfig\n",
        "from transformers.data.data_collator import DataCollator, DataCollatorWithPadding, default_data_collator\n",
        "from transformers.debug_utils import DebugOption, DebugUnderflowOverflow\n",
        "from transformers.deepspeed import deepspeed_init, is_deepspeed_zero3_enabled\n",
        "from transformers.dependency_versions_check import dep_version_check\n",
        "from transformers.modelcard import TrainingSummary\n",
        "from transformers.modeling_utils import PreTrainedModel, load_sharded_checkpoint, unwrap_model\n",
        "from transformers.models.auto.modeling_auto import MODEL_FOR_CAUSAL_LM_MAPPING_NAMES, MODEL_MAPPING_NAMES\n",
        "from transformers.optimization import Adafactor, get_scheduler\n",
        "from transformers.pytorch_utils import ALL_LAYERNORM_LAYERS, is_torch_greater_or_equal_than_1_10, is_torch_less_than_1_11\n",
        "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
        "from transformers.trainer_callback import (\n",
        "    CallbackHandler,\n",
        "    DefaultFlowCallback,\n",
        "    PrinterCallback,\n",
        "    ProgressCallback,\n",
        "    TrainerCallback,\n",
        "    TrainerControl,\n",
        "    TrainerState,\n",
        ")\n",
        "from transformers.trainer_pt_utils import (\n",
        "    DistributedLengthGroupedSampler,\n",
        "    DistributedSamplerWithLoop,\n",
        "    DistributedTensorGatherer,\n",
        "    IterableDatasetShard,\n",
        "    LabelSmoother,\n",
        "    LengthGroupedSampler,\n",
        "    SequentialDistributedSampler,\n",
        "    ShardSampler,\n",
        "    distributed_broadcast_scalars,\n",
        "    distributed_concat,\n",
        "    find_batch_size,\n",
        "    get_module_class_from_name,\n",
        "    get_parameter_names,\n",
        "    nested_concat,\n",
        "    nested_detach,\n",
        "    nested_numpify,\n",
        "    nested_truncate,\n",
        "    nested_xla_mesh_reduce,\n",
        "    reissue_pt_warnings,\n",
        ")\n",
        "from transformers.trainer_utils import (\n",
        "    PREFIX_CHECKPOINT_DIR,\n",
        "    BestRun,\n",
        "    EvalLoopOutput,\n",
        "    EvalPrediction,\n",
        "    FSDPOption,\n",
        "    HPSearchBackend,\n",
        "    HubStrategy,\n",
        "    IntervalStrategy,\n",
        "    PredictionOutput,\n",
        "    RemoveColumnsCollator,\n",
        "    ShardedDDPOption,\n",
        "    TrainerMemoryTracker,\n",
        "    TrainOutput,\n",
        "    default_compute_objective,\n",
        "    default_hp_space,\n",
        "    denumpify_detensorize,\n",
        "    enable_full_determinism,\n",
        "    find_executable_batch_size,\n",
        "    get_last_checkpoint,\n",
        "    has_length,\n",
        "    number_of_arguments,\n",
        "    seed_worker,\n",
        "    set_seed,\n",
        "    speed_metrics,\n",
        ")\n",
        "from transformers.training_args import OptimizerNames, ParallelMode, TrainingArguments\n",
        "from transformers.utils import (\n",
        "    CONFIG_NAME,\n",
        "    WEIGHTS_INDEX_NAME,\n",
        "    WEIGHTS_NAME,\n",
        "    find_labels,\n",
        "    get_full_repo_name,\n",
        "    is_apex_available,\n",
        "    is_datasets_available,\n",
        "    is_in_notebook,\n",
        "    is_ipex_available,\n",
        "    is_sagemaker_dp_enabled,\n",
        "    is_sagemaker_mp_enabled,\n",
        "    is_torch_tensorrt_fx_available,\n",
        "    is_torch_tpu_available,\n",
        "    is_torchdynamo_available,\n",
        "    logging,\n",
        ")\n",
        "from transformers.utils.generic import ContextManagers\n",
        "\n",
        "\n",
        "_is_native_cpu_amp_available = is_torch_greater_or_equal_than_1_10\n",
        "\n",
        "DEFAULT_CALLBACKS = [DefaultFlowCallback]\n",
        "DEFAULT_PROGRESS_CALLBACK = ProgressCallback\n",
        "\n",
        "if is_in_notebook():\n",
        "    from transformers.utils.notebook import NotebookProgressCallback\n",
        "\n",
        "    DEFAULT_PROGRESS_CALLBACK = NotebookProgressCallback\n",
        "\n",
        "if is_apex_available():\n",
        "    from apex import amp\n",
        "\n",
        "if is_datasets_available():\n",
        "    import datasets\n",
        "\n",
        "if is_torch_tpu_available(check_device=False):\n",
        "    import torch_xla.core.xla_model as xm\n",
        "    import torch_xla.debug.metrics as met\n",
        "    import torch_xla.distributed.parallel_loader as pl\n",
        "\n",
        "if is_fairscale_available():\n",
        "    dep_version_check(\"fairscale\")\n",
        "    import fairscale\n",
        "    from fairscale.nn.data_parallel import FullyShardedDataParallel as FullyShardedDDP\n",
        "    from fairscale.nn.data_parallel import ShardedDataParallel as ShardedDDP\n",
        "    from fairscale.nn.wrap import auto_wrap\n",
        "    from fairscale.optim import OSS\n",
        "    from fairscale.optim.grad_scaler import ShardedGradScaler\n",
        "\n",
        "\n",
        "if is_sagemaker_mp_enabled():\n",
        "    import smdistributed.modelparallel.torch as smp\n",
        "    from smdistributed.modelparallel import __version__ as SMP_VERSION\n",
        "\n",
        "    IS_SAGEMAKER_MP_POST_1_10 = version.parse(SMP_VERSION) >= version.parse(\"1.10\")\n",
        "\n",
        "    from transformers.trainer_pt_utils import smp_forward_backward, smp_forward_only, smp_gather, smp_nested_concat\n",
        "else:\n",
        "    IS_SAGEMAKER_MP_POST_1_10 = False\n",
        "\n",
        "\n",
        "if TYPE_CHECKING:\n",
        "    import optuna\n",
        "\n",
        "logger = logging.get_logger(__name__)\n",
        "\n",
        "\n",
        "# Name of the files used for checkpointing\n",
        "TRAINING_ARGS_NAME = \"training_args.bin\"\n",
        "TRAINER_STATE_NAME = \"trainer_state.json\"\n",
        "OPTIMIZER_NAME = \"optimizer.pt\"\n",
        "SCHEDULER_NAME = \"scheduler.pt\"\n",
        "SCALER_NAME = \"scaler.pt\"\n",
        "\n",
        "####From Trainer source code, Transformers v4.23.1\n",
        "class ExperienceReplayTrainer(Trainer):\n",
        "\n",
        "    ##################################################################\n",
        "    #######  EXPERIENCE REPLAY MODIFICATION STARTS HERE  #############\n",
        "    ##################################################################\n",
        "\n",
        "    def __init__(self, old_dataset, replay_freq, *args, **kwargs):  #we pass the old dataset and replay freq to init\n",
        "        self.old_dataset = old_dataset\n",
        "        self.replay_freq = replay_freq\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def get_old_dataloader(self) -> DataLoader:\n",
        "        \"\"\"\n",
        "        dataloader for experience replay. NOTE: shuffle=True\n",
        "        \"\"\"\n",
        "        if self.old_dataset is None:\n",
        "            raise ValueError(\"Trainer: experience replay requires a old_dataset.\")\n",
        "\n",
        "        old_dataset = self.old_dataset\n",
        "        data_collator = self.data_collator\n",
        "        if is_datasets_available() and isinstance(old_dataset, datasets.Dataset):\n",
        "            old_dataset = self._remove_unused_columns(old_dataset, description=\"experience replay\")\n",
        "        else:\n",
        "            data_collator = self._get_collator_with_removed_columns(data_collator, description=\"experience replay\")\n",
        "\n",
        "        if isinstance(old_dataset, torch.utils.data.IterableDataset):\n",
        "            if self.args.world_size > 1:\n",
        "                old_dataset = IterableDatasetShard(\n",
        "                    old_dataset,\n",
        "                    batch_size=self._train_batch_size,\n",
        "                    drop_last=self.args.dataloader_drop_last,\n",
        "                    num_processes=self.args.world_size,\n",
        "                    process_index=self.args.process_index,\n",
        "                )\n",
        "\n",
        "            return DataLoader(\n",
        "                old_dataset,\n",
        "                batch_size=self.args.per_device_train_batch_size,\n",
        "                shuffle=True,\n",
        "                collate_fn=data_collator,\n",
        "                num_workers=self.args.dataloader_num_workers,\n",
        "                pin_memory=self.args.dataloader_pin_memory,\n",
        "            )\n",
        "\n",
        "        return DataLoader(\n",
        "            old_dataset,\n",
        "            batch_size=self._train_batch_size,\n",
        "            shuffle=True,\n",
        "            collate_fn=data_collator,\n",
        "            drop_last=self.args.dataloader_drop_last,\n",
        "            num_workers=self.args.dataloader_num_workers,\n",
        "            pin_memory=self.args.dataloader_pin_memory,\n",
        "            worker_init_fn=seed_worker,\n",
        "        )\n",
        "\n",
        "    ##################################################################\n",
        "    #######  EXPERIENCE REPLAY MODIFICATION ENDS HERE  ###############\n",
        "    ##################################################################\n",
        "\n",
        "    def _inner_training_loop(\n",
        "        self, batch_size=None, args=None, resume_from_checkpoint=None, trial=None, ignore_keys_for_eval=None\n",
        "    ):\n",
        "        self._train_batch_size = batch_size\n",
        "        # Data loader and number of training steps\n",
        "        train_dataloader = self.get_train_dataloader()\n",
        "\n",
        "        ##################################################################\n",
        "        #######  EXPERIENCE REPLAY MODIFICATION STARTS HERE  #############\n",
        "        ##################################################################       \n",
        "\n",
        "        old_dataloader = self.get_old_dataloader()\n",
        "\n",
        "        ##################################################################\n",
        "        #######  EXPERIENCE REPLAY MODIFICATION ENDS HERE  ###############\n",
        "        ################################################################## \n",
        "\n",
        "        # Setting up training control variables:\n",
        "        # number of training epochs: num_train_epochs\n",
        "        # number of training steps per epoch: num_update_steps_per_epoch\n",
        "        # total number of training steps to execute: max_steps\n",
        "        total_train_batch_size = args.train_batch_size * args.gradient_accumulation_steps * args.world_size\n",
        "\n",
        "        len_dataloader = None\n",
        "        if has_length(train_dataloader):\n",
        "            len_dataloader = len(train_dataloader)\n",
        "            num_update_steps_per_epoch = len_dataloader // args.gradient_accumulation_steps\n",
        "            num_update_steps_per_epoch = max(num_update_steps_per_epoch, 1)\n",
        "            num_examples = self.num_examples(train_dataloader)\n",
        "            if args.max_steps > 0:\n",
        "                max_steps = args.max_steps\n",
        "                num_train_epochs = args.max_steps // num_update_steps_per_epoch + int(\n",
        "                    args.max_steps % num_update_steps_per_epoch > 0\n",
        "                )\n",
        "                # May be slightly incorrect if the last batch in the training dataloader has a smaller size but it's\n",
        "                # the best we can do.\n",
        "                num_train_samples = args.max_steps * total_train_batch_size\n",
        "            else:\n",
        "                max_steps = math.ceil(args.num_train_epochs * num_update_steps_per_epoch)\n",
        "                num_train_epochs = math.ceil(args.num_train_epochs)\n",
        "                num_train_samples = self.num_examples(train_dataloader) * args.num_train_epochs\n",
        "        elif args.max_steps > 0:  # Rely on max_steps when dataloader does not have a working size\n",
        "            max_steps = args.max_steps\n",
        "            # Setting a very large number of epochs so we go as many times as necessary over the iterator.\n",
        "            num_train_epochs = sys.maxsize\n",
        "            num_update_steps_per_epoch = max_steps\n",
        "            num_examples = total_train_batch_size * args.max_steps\n",
        "            num_train_samples = args.max_steps * total_train_batch_size\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"args.max_steps must be set to a positive value if dataloader does not have a length, was\"\n",
        "                f\" {args.max_steps}\"\n",
        "            )\n",
        "\n",
        "        if DebugOption.UNDERFLOW_OVERFLOW in self.args.debug:\n",
        "            if self.args.n_gpu > 1:\n",
        "                # nn.DataParallel(model) replicates the model, creating new variables and module\n",
        "                # references registered here no longer work on other gpus, breaking the module\n",
        "                raise ValueError(\n",
        "                    \"Currently --debug underflow_overflow is not supported under DP. Please use DDP\"\n",
        "                    \" (torch.distributed.launch).\"\n",
        "                )\n",
        "            else:\n",
        "                debug_overflow = DebugUnderflowOverflow(self.model)  # noqa\n",
        "\n",
        "        delay_optimizer_creation = (\n",
        "            self.sharded_ddp is not None\n",
        "            and self.sharded_ddp != ShardedDDPOption.SIMPLE\n",
        "            or is_sagemaker_mp_enabled()\n",
        "            or self.fsdp is not None\n",
        "        )\n",
        "        if args.deepspeed:\n",
        "            deepspeed_engine, optimizer, lr_scheduler = deepspeed_init(\n",
        "                self, num_training_steps=max_steps, resume_from_checkpoint=resume_from_checkpoint\n",
        "            )\n",
        "            self.model = deepspeed_engine.module\n",
        "            self.model_wrapped = deepspeed_engine\n",
        "            self.deepspeed = deepspeed_engine\n",
        "            self.optimizer = optimizer\n",
        "            self.lr_scheduler = lr_scheduler\n",
        "        elif not delay_optimizer_creation:\n",
        "            self.create_optimizer_and_scheduler(num_training_steps=max_steps)\n",
        "\n",
        "        self.state = TrainerState()\n",
        "        self.state.is_hyper_param_search = trial is not None\n",
        "\n",
        "        # Activate gradient checkpointing if needed\n",
        "        if args.gradient_checkpointing:\n",
        "            self.model.gradient_checkpointing_enable()\n",
        "\n",
        "        model = self._wrap_model(self.model_wrapped)\n",
        "\n",
        "        if is_sagemaker_mp_enabled() and resume_from_checkpoint is not None:\n",
        "            self._load_from_checkpoint(resume_from_checkpoint, model)\n",
        "\n",
        "        # for the rest of this function `model` is the outside model, whether it was wrapped or not\n",
        "        if model is not self.model:\n",
        "            self.model_wrapped = model\n",
        "\n",
        "        if delay_optimizer_creation:\n",
        "            self.create_optimizer_and_scheduler(num_training_steps=max_steps)\n",
        "\n",
        "        # Check if saved optimizer or scheduler states exist\n",
        "        self._load_optimizer_and_scheduler(resume_from_checkpoint)\n",
        "\n",
        "        # important: at this point:\n",
        "        # self.model         is the Transformers Model\n",
        "        # self.model_wrapped is DDP(Transformers Model), Deepspeed(Transformers Model), etc.\n",
        "\n",
        "        # Train!\n",
        "        logger.info(\"***** Running training *****\")\n",
        "        logger.info(f\"  Num examples = {num_examples}\")\n",
        "        logger.info(f\"  Num Epochs = {num_train_epochs}\")\n",
        "        logger.info(f\"  Instantaneous batch size per device = {args.per_device_train_batch_size}\")\n",
        "        logger.info(f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_train_batch_size}\")\n",
        "        logger.info(f\"  Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\n",
        "        logger.info(f\"  Total optimization steps = {max_steps}\")\n",
        "\n",
        "        self.state.epoch = 0\n",
        "        start_time = time.time()\n",
        "        epochs_trained = 0\n",
        "        steps_trained_in_current_epoch = 0\n",
        "        steps_trained_progress_bar = None\n",
        "\n",
        "        # Check if continuing training from a checkpoint\n",
        "        if resume_from_checkpoint is not None and os.path.isfile(\n",
        "            os.path.join(resume_from_checkpoint, TRAINER_STATE_NAME)\n",
        "        ):\n",
        "            self.state = TrainerState.load_from_json(os.path.join(resume_from_checkpoint, TRAINER_STATE_NAME))\n",
        "            epochs_trained = self.state.global_step // num_update_steps_per_epoch\n",
        "            if not args.ignore_data_skip:\n",
        "                steps_trained_in_current_epoch = self.state.global_step % (num_update_steps_per_epoch)\n",
        "                steps_trained_in_current_epoch *= args.gradient_accumulation_steps\n",
        "            else:\n",
        "                steps_trained_in_current_epoch = 0\n",
        "\n",
        "            logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
        "            logger.info(f\"  Continuing training from epoch {epochs_trained}\")\n",
        "            logger.info(f\"  Continuing training from global step {self.state.global_step}\")\n",
        "            if not args.ignore_data_skip:\n",
        "                logger.info(\n",
        "                    f\"  Will skip the first {epochs_trained} epochs then the first {steps_trained_in_current_epoch} \"\n",
        "                    \"batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` \"\n",
        "                    \"flag to your launch command, but you will resume the training on data already seen by your model.\"\n",
        "                )\n",
        "                if self.is_local_process_zero() and not args.disable_tqdm:\n",
        "                    steps_trained_progress_bar = tqdm(total=steps_trained_in_current_epoch)\n",
        "                    steps_trained_progress_bar.set_description(\"Skipping the first batches\")\n",
        "\n",
        "        # Update the references\n",
        "        self.callback_handler.model = self.model\n",
        "        self.callback_handler.optimizer = self.optimizer\n",
        "        self.callback_handler.lr_scheduler = self.lr_scheduler\n",
        "        self.callback_handler.train_dataloader = train_dataloader\n",
        "        self.state.trial_name = self.hp_name(trial) if self.hp_name is not None else None\n",
        "        if trial is not None:\n",
        "            assignments = trial.assignments if self.hp_search_backend == HPSearchBackend.SIGOPT else trial\n",
        "            self.state.trial_params = hp_params(assignments)\n",
        "        else:\n",
        "            self.state.trial_params = None\n",
        "        # This should be the same if the state has been saved but in case the training arguments changed, it's safer\n",
        "        # to set this after the load.\n",
        "        self.state.max_steps = max_steps\n",
        "        self.state.num_train_epochs = num_train_epochs\n",
        "        self.state.is_local_process_zero = self.is_local_process_zero()\n",
        "        self.state.is_world_process_zero = self.is_world_process_zero()\n",
        "\n",
        "        # tr_loss is a tensor to avoid synchronization of TPUs through .item()\n",
        "        tr_loss = torch.tensor(0.0).to(args.device)\n",
        "        # _total_loss_scalar is updated everytime .item() has to be called on tr_loss and stores the sum of all losses\n",
        "        self._total_loss_scalar = 0.0\n",
        "        self._globalstep_last_logged = self.state.global_step\n",
        "        model.zero_grad()\n",
        "\n",
        "        self.control = self.callback_handler.on_train_begin(args, self.state, self.control)\n",
        "\n",
        "        # Skip the first epochs_trained epochs to get the random state of the dataloader at the right point.\n",
        "        if not args.ignore_data_skip:\n",
        "            for epoch in range(epochs_trained):\n",
        "                is_random_sampler = hasattr(train_dataloader, \"sampler\") and isinstance(\n",
        "                    train_dataloader.sampler, RandomSampler\n",
        "                )\n",
        "                if is_torch_less_than_1_11 or not is_random_sampler:\n",
        "                    # We just need to begin an iteration to create the randomization of the sampler.\n",
        "                    # That was before PyTorch 1.11 however...\n",
        "                    for _ in train_dataloader:\n",
        "                        break\n",
        "                else:\n",
        "                    # Otherwise we need to call the whooooole sampler cause there is some random operation added\n",
        "                    # AT THE VERY END!\n",
        "                    _ = list(train_dataloader.sampler)\n",
        "\n",
        "        for epoch in range(epochs_trained, num_train_epochs):\n",
        "            if isinstance(train_dataloader, DataLoader) and isinstance(train_dataloader.sampler, DistributedSampler):\n",
        "                train_dataloader.sampler.set_epoch(epoch)\n",
        "            elif hasattr(train_dataloader, \"dataset\") and isinstance(train_dataloader.dataset, IterableDatasetShard):\n",
        "                train_dataloader.dataset.set_epoch(epoch)\n",
        "\n",
        "            if is_torch_tpu_available():\n",
        "                parallel_loader = pl.ParallelLoader(train_dataloader, [args.device]).per_device_loader(args.device)\n",
        "                epoch_iterator = parallel_loader\n",
        "            else:\n",
        "                epoch_iterator = train_dataloader\n",
        "\n",
        "            # Reset the past mems state at the beginning of each epoch if necessary.\n",
        "            if args.past_index >= 0:\n",
        "                self._past = None\n",
        "\n",
        "            steps_in_epoch = (\n",
        "                len(epoch_iterator)\n",
        "                if len_dataloader is not None\n",
        "                else args.max_steps * args.gradient_accumulation_steps\n",
        "            )\n",
        "            self.control = self.callback_handler.on_epoch_begin(args, self.state, self.control)\n",
        "\n",
        "            if epoch == epochs_trained and resume_from_checkpoint is not None and steps_trained_in_current_epoch == 0:\n",
        "                self._load_rng_state(resume_from_checkpoint)\n",
        "\n",
        "            step = -1\n",
        "            for step, inputs in enumerate(epoch_iterator):\n",
        "\n",
        "                ##################################################################\n",
        "                #######  EXPERIENCE REPLAY MODIFICATION STARTS HERE  #############\n",
        "                ##################################################################\n",
        "\n",
        "                #### Note: there might be a OOM problem because we are loading two\n",
        "                #### batches in the same step: inputs and old_inputs. If it does\n",
        "                #### not work, try to move 'inputs' back to cpu and then reload it\n",
        "                #### to the gpu when you're done with 'old_inputs'.\n",
        "\n",
        "                #option 1 (used in the original paper)\n",
        "                #inputs_cp = copy.deepcopy(inputs)\n",
        "                #del inputs\n",
        "\n",
        "                #option 2 (experimental if option 1 won't work)\n",
        "                #for input_tensor in inputs:\n",
        "                #     input_tensor.to(\"cpu\")\n",
        "                #//experience replay code chunk here\n",
        "                #for input_tensor in inputs:\n",
        "                #     input_tensor.to(self.args.device)\n",
        "\n",
        "                if (step+1) % replay_freq == 0:           #every replay_freq steps\n",
        "\n",
        "                    #sample a new batch from the old data\n",
        "                    old_inputs = next(iter(old_dataloader))    # <<------ load next random batch\n",
        "                    self.optimizer.zero_grad()                 # clear out the gradients (by default they accumulate)\n",
        "                    tr_loss_step = self.training_step(model, old_inputs)\n",
        "                    tr_loss += tr_loss_step\n",
        "                    del old_inputs\n",
        "\n",
        "                ##################################################################\n",
        "                #######  EXPERIENCE REPLAY MODIFICATION ENDS HERE  ###############\n",
        "                ##################################################################\n",
        "\n",
        "                # Skip past any already trained steps if resuming training\n",
        "                if steps_trained_in_current_epoch > 0:\n",
        "                    steps_trained_in_current_epoch -= 1\n",
        "                    if steps_trained_progress_bar is not None:\n",
        "                        steps_trained_progress_bar.update(1)\n",
        "                    if steps_trained_in_current_epoch == 0:\n",
        "                        self._load_rng_state(resume_from_checkpoint)\n",
        "                    continue\n",
        "                elif steps_trained_progress_bar is not None:\n",
        "                    steps_trained_progress_bar.close()\n",
        "                    steps_trained_progress_bar = None\n",
        "\n",
        "                if step % args.gradient_accumulation_steps == 0:\n",
        "                    self.control = self.callback_handler.on_step_begin(args, self.state, self.control)\n",
        "\n",
        "                if (\n",
        "                    ((step + 1) % args.gradient_accumulation_steps != 0)\n",
        "                    and args.local_rank != -1\n",
        "                    and args._no_sync_in_gradient_accumulation\n",
        "                ):\n",
        "                    # Avoid unnecessary DDP synchronization since there will be no backward pass on this example.\n",
        "                    with model.no_sync():\n",
        "                        tr_loss_step = self.training_step(model, inputs)\n",
        "                else:\n",
        "                    tr_loss_step = self.training_step(model, inputs)\n",
        "\n",
        "                if (\n",
        "                    args.logging_nan_inf_filter\n",
        "                    and not is_torch_tpu_available()\n",
        "                    and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step))\n",
        "                ):\n",
        "                    # if loss is nan or inf simply add the average of previous logged losses\n",
        "                    tr_loss += tr_loss / (1 + self.state.global_step - self._globalstep_last_logged)\n",
        "                else:\n",
        "                    tr_loss += tr_loss_step\n",
        "\n",
        "                self.current_flos += float(self.floating_point_ops(inputs))\n",
        "\n",
        "                # Optimizer step for deepspeed must be called on every step regardless of the value of gradient_accumulation_steps\n",
        "                if self.deepspeed:\n",
        "                    self.deepspeed.step()\n",
        "\n",
        "                if (step + 1) % args.gradient_accumulation_steps == 0 or (\n",
        "                    # last step in epoch but step is always smaller than gradient_accumulation_steps\n",
        "                    steps_in_epoch <= args.gradient_accumulation_steps\n",
        "                    and (step + 1) == steps_in_epoch\n",
        "                ):\n",
        "                    # Gradient clipping\n",
        "                    if args.max_grad_norm is not None and args.max_grad_norm > 0 and not self.deepspeed:\n",
        "                        # deepspeed does its own clipping\n",
        "\n",
        "                        if self.do_grad_scaling:\n",
        "                            # Reduce gradients first for XLA\n",
        "                            if is_torch_tpu_available():\n",
        "                                gradients = xm._fetch_gradients(self.optimizer)\n",
        "                                xm.all_reduce(\"sum\", gradients, scale=1.0 / xm.xrt_world_size())\n",
        "                            # AMP: gradients need unscaling\n",
        "                            self.scaler.unscale_(self.optimizer)\n",
        "\n",
        "                        if is_sagemaker_mp_enabled() and args.fp16:\n",
        "                            self.optimizer.clip_master_grads(args.max_grad_norm)\n",
        "                        elif hasattr(self.optimizer, \"clip_grad_norm\"):\n",
        "                            # Some optimizers (like the sharded optimizer) have a specific way to do gradient clipping\n",
        "                            self.optimizer.clip_grad_norm(args.max_grad_norm)\n",
        "                        elif hasattr(model, \"clip_grad_norm_\"):\n",
        "                            # Some models (like FullyShardedDDP) have a specific way to do gradient clipping\n",
        "                            model.clip_grad_norm_(args.max_grad_norm)\n",
        "                        else:\n",
        "                            # Revert to normal clipping otherwise, handling Apex or full precision\n",
        "                            nn.utils.clip_grad_norm_(\n",
        "                                amp.master_params(self.optimizer) if self.use_apex else model.parameters(),\n",
        "                                args.max_grad_norm,\n",
        "                            )\n",
        "\n",
        "                    # Optimizer step\n",
        "                    optimizer_was_run = True\n",
        "                    if self.deepspeed:\n",
        "                        pass  # called outside the loop\n",
        "                    elif is_torch_tpu_available():\n",
        "                        if self.do_grad_scaling:\n",
        "                            self.scaler.step(self.optimizer)\n",
        "                            self.scaler.update()\n",
        "                        else:\n",
        "                            xm.optimizer_step(self.optimizer)\n",
        "                    elif self.do_grad_scaling:\n",
        "                        scale_before = self.scaler.get_scale()\n",
        "                        self.scaler.step(self.optimizer)\n",
        "                        self.scaler.update()\n",
        "                        scale_after = self.scaler.get_scale()\n",
        "                        optimizer_was_run = scale_before <= scale_after\n",
        "                    else:\n",
        "                        self.optimizer.step()\n",
        "\n",
        "                    if optimizer_was_run and not self.deepspeed:\n",
        "                        self.lr_scheduler.step()\n",
        "\n",
        "                    model.zero_grad()\n",
        "                    self.state.global_step += 1\n",
        "                    self.state.epoch = epoch + (step + 1) / steps_in_epoch\n",
        "                    self.control = self.callback_handler.on_step_end(args, self.state, self.control)\n",
        "\n",
        "                    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n",
        "                else:\n",
        "                    self.control = self.callback_handler.on_substep_end(args, self.state, self.control)\n",
        "\n",
        "                if self.control.should_epoch_stop or self.control.should_training_stop:\n",
        "                    break\n",
        "            if step < 0:\n",
        "                logger.warning(\n",
        "                    \"There seems to be not a single sample in your epoch_iterator, stopping training at step\"\n",
        "                    f\" {self.state.global_step}! This is expected if you're using an IterableDataset and set\"\n",
        "                    f\" num_steps ({max_steps}) higher than the number of available samples.\"\n",
        "                )\n",
        "                self.control.should_training_stop = True\n",
        "\n",
        "            self.control = self.callback_handler.on_epoch_end(args, self.state, self.control)\n",
        "            self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n",
        "\n",
        "            if DebugOption.TPU_METRICS_DEBUG in self.args.debug:\n",
        "                if is_torch_tpu_available():\n",
        "                    # tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\n",
        "                    xm.master_print(met.metrics_report())\n",
        "                else:\n",
        "                    logger.warning(\n",
        "                        \"You enabled PyTorch/XLA debug metrics but you don't have a TPU \"\n",
        "                        \"configured. Check your training configuration if this is unexpected.\"\n",
        "                    )\n",
        "            if self.control.should_training_stop:\n",
        "                break\n",
        "\n",
        "        if args.past_index and hasattr(self, \"_past\"):\n",
        "            # Clean the state at the end of training\n",
        "            delattr(self, \"_past\")\n",
        "\n",
        "        logger.info(\"\\n\\nTraining completed. Do not forget to share your model on huggingface.co/models =)\\n\\n\")\n",
        "        if args.load_best_model_at_end and self.state.best_model_checkpoint is not None:\n",
        "            # Wait for everyone to get here so we are sur the model has been saved by process 0.\n",
        "            if is_torch_tpu_available():\n",
        "                xm.rendezvous(\"load_best_model_at_end\")\n",
        "            elif args.local_rank != -1:\n",
        "                dist.barrier()\n",
        "            elif is_sagemaker_mp_enabled():\n",
        "                smp.barrier()\n",
        "\n",
        "            self._load_best_model()\n",
        "\n",
        "        # add remaining tr_loss\n",
        "        self._total_loss_scalar += tr_loss.item()\n",
        "        train_loss = self._total_loss_scalar / self.state.global_step\n",
        "\n",
        "        metrics = speed_metrics(\"train\", start_time, num_samples=num_train_samples, num_steps=self.state.max_steps)\n",
        "        self.store_flos()\n",
        "        metrics[\"total_flos\"] = self.state.total_flos\n",
        "        metrics[\"train_loss\"] = train_loss\n",
        "\n",
        "        self.is_in_train = False\n",
        "\n",
        "        self._memory_tracker.stop_and_update_metrics(metrics)\n",
        "\n",
        "        self.log(metrics)\n",
        "\n",
        "        self.control = self.callback_handler.on_train_end(args, self.state, self.control)\n",
        "\n",
        "        return TrainOutput(self.state.global_step, train_loss, metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pfTtp6pd8XD"
      },
      "source": [
        "## **Layer-wise Learning Rate Decay (LLRD)**\n",
        "\n",
        "LLRD is a method that applies higher learning rates for top layers and lower learning rates for bottom layers. This is accomplished by setting the learning rate of the top layer and using a multiplicative decay rate to decrease the learning rate layer-by-layer from top to bottom.\n",
        "\n",
        "The goal is to modify the lower layers that encode more general information less than the top layers that are more specific to the pre-training task. This method is adopted in fine-tuning several recent pre-trained models, including XLNet and ELECTRA, but not BERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80RpXz8Dd0pT"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AdamW, \n",
        "    AutoConfig, \n",
        "    AutoModelForSequenceClassification,\n",
        "    get_cosine_schedule_with_warmup,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "from transformers import logging\n",
        "logging.set_verbosity_warning()\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "config = AutoConfig.from_pretrained(original_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvxMlSh5d0LA"
      },
      "outputs": [],
      "source": [
        "def get_optimizer_grouped_parameters(model, model_type, learning_rate, weight_decay, layerwise_learning_rate_decay):\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    # initialize lr for task specific layer\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if \"classifier\" in n or \"pooler\" in n],\n",
        "            \"weight_decay\": 0.0,\n",
        "            \"lr\": learning_rate,\n",
        "        },\n",
        "    ]\n",
        "    # initialize lrs for every layer\n",
        "    num_layers = model.config.num_hidden_layers\n",
        "    layers = [getattr(model, model_type).embeddings] + list(getattr(model, model_type).encoder.layer)\n",
        "    layers.reverse()\n",
        "    lr = learning_rate\n",
        "    for layer in layers:\n",
        "        lr *= layerwise_learning_rate_decay\n",
        "        optimizer_grouped_parameters += [\n",
        "            {\n",
        "                \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": weight_decay,\n",
        "                \"lr\": lr,\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": 0.0,\n",
        "                \"lr\": lr,\n",
        "            },\n",
        "        ]\n",
        "    return optimizer_grouped_parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YK8NodGseL1z"
      },
      "outputs": [],
      "source": [
        "grouped_optimizer_params = get_optimizer_grouped_parameters(model=model, \n",
        "                                                            model_type='bert', \n",
        "                                                            learning_rate=learning_rate, \n",
        "                                                            weight_decay=weight_decay, \n",
        "                                                            layerwise_learning_rate_decay=layerwise_learning_rate_decay)\n",
        "optimizer = AdamW(params=grouped_optimizer_params, \n",
        "                  lr=learning_rate, \n",
        "                  eps=adam_epsilon, \n",
        "                  correct_bias=not use_bertadam)\n",
        "\n",
        "tot_steps = math.ceil(len(train_dataset)/batch_size)*epochs\n",
        "num_warmup_steps = int(warmup_ratio*tot_steps)\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=num_warmup_steps,\n",
        "                                            num_training_steps=epochs)\n",
        "\n",
        "if cf_is_on[\"llrd\"]:\n",
        "  optimizers = (optimizer,scheduler)\n",
        "else:\n",
        "  optimizers = (None, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri2BIQKqjfHm"
      },
      "source": [
        "#Training "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDLs73HcIHk5"
      },
      "source": [
        "We need to define a data_collator. This is just a small helper that will help us batch different samples of the dataset together into an object that PyTorch knows how to perform backprop on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTgWPa9Dipk2"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=mlm_probability,\n",
        "    pad_to_multiple_of=8 if pad_to_multiple_of_8 else None,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glSVOT1BpD7v"
      },
      "source": [
        "## Arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpvnFFmZJD-N"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir = output_model_path,\n",
        "    save_strategy = \"epoch\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=epochs,\n",
        "    per_device_train_batch_size = batch_size,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True,\n",
        "    disable_tqdm=False\n",
        ")\n",
        "\n",
        "if cf_is_on[\"experience_replay\"]:\n",
        "  raw_datasets_old = load_from_disk(old_corpus_path)\n",
        "  old_dataset = prepare_dataset_for_mlm(raw_datasets_old,tokenizer)  #N.B. we are assuming that the old and new model share the same tokenizer. If not, use old tokenizer\n",
        "  trainer = ExperienceReplayTrainer(\n",
        "      model = model,\n",
        "      args = training_args,\n",
        "      data_collator = data_collator,\n",
        "      train_dataset = train_dataset,\n",
        "      old_dataset = old_dataset,\n",
        "      replay_freq = replay_freq,\n",
        "      optimizers= optimizers\n",
        "  )\n",
        "else:\n",
        "  trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    optimizers= optimizers\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6sASa36Nf-N"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmaHZXzmkNtJ"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZkooHz1-_2h"
      },
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDNgPls7_l13"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"/content/gdrive/MyDrive/Colab Environments/biobert_models/newmodel\") # remember to rename newmodel after saving to leave this path empty for the next iteration\n",
        "tokenizer.save_pretrained(\"/content/gdrive/MyDrive/Colab Environments/biobert_models/newmodel\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalize session info and download"
      ],
      "metadata": {
        "id": "DgwaQ7uITFXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session_info['original_checkpoint'] = [original_model]\n",
        "session_info['cf'] = cf_is_on\n",
        "session_info['training_arguments'] = training_args\n",
        "session_info['time_end'] = time.strftime(\"%H:%M:%S\", time.localtime())\n",
        "\n",
        "with open(f'/content/session_info.json', \"w\") as outfile:\n",
        "    outfile.write(json.dumps(session_info, indent=4))\n",
        "files.download(f'/content/session_info.json')"
      ],
      "metadata": {
        "id": "NNNE8WGBR7m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you don't want to check the model, unassign the runtime here to save compute units"
      ],
      "metadata": {
        "id": "JOWpVMJc3Yx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "Wo3uihbtTWIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0caceCy_p1-"
      },
      "source": [
        "# (Optional) Model check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ltXgXyCbAJLY"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    \"fill-mask\",\n",
        "    model = \"/content/gdrive/MyDrive/Colab Environments/biobert_models/newmodel\",\n",
        "    tokenizer = original_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UIvgZ3S6AO0z"
      },
      "outputs": [],
      "source": [
        "# The sun <mask>.\n",
        "\n",
        "fill_mask(\"Un tumore cerebrale consiste nella crescita anomale di cellule nei tessuti del [MASK], che puÃ² essere benigna o maligna\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "qepj_jjW3gNM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}