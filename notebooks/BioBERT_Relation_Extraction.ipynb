{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IVN-RIN/bio-med-BIT/blob/main/notebooks/BioBERT_Relation_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BioBIT Fine-Tuning Experiment For <u>Relation Extraction</u>**\n",
        "\n",
        "*Tommaso Buonocore, University of Pavia, 2022*\n",
        "\n",
        "*Last edited: 16/11/2022*"
      ],
      "metadata": {
        "id": "A01U9IQdNGBi"
      },
      "id": "A01U9IQdNGBi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGJbZFuimMmA"
      },
      "source": [
        "#Initialization"
      ],
      "id": "AGJbZFuimMmA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Short string describing the current run"
      ],
      "metadata": {
        "id": "C4Pp_wQ3NK0p"
      },
      "id": "C4Pp_wQ3NK0p"
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_name = \"Chemprot-RE reg3plus only\""
      ],
      "metadata": {
        "id": "-Vm6QPViNMlR"
      },
      "id": "-Vm6QPViNMlR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5an4xejDV-C"
      },
      "source": [
        "## Imports"
      ],
      "id": "q5an4xejDV-C"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "funny-monster"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# If running on colab, install first\n",
        "!pip install datasets evaluate sklearn transformers\n",
        "\n",
        "# Google Colab only\n",
        "from IPython.display import display, HTML\n",
        "from google.colab import files\n",
        "\n",
        "# General\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import sklearn.metrics\n",
        "import evaluate\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "from io import StringIO\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "# HuggingFace Transformers\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, TrainingArguments, Trainer, EarlyStoppingCallback, set_seed\n",
        "\n",
        "# Set device to GPU Cuda if available \n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "id": "funny-monster"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Session Info"
      ],
      "metadata": {
        "id": "eloncrpiNsx5"
      },
      "id": "eloncrpiNsx5"
    },
    {
      "cell_type": "code",
      "source": [
        "session_info = json.loads(os.popen(\"curl curl ipinfo.io\").read())\n",
        "if device=='cuda':\n",
        "  gpu_info = pd.read_csv(StringIO(os.popen(\"nvidia-smi --query-gpu=gpu_name,memory.total --format=csv\").read()),names=[\"name\",\"memory\"],header=0)\n",
        "  session_info[f'gpus'] = [{'name': row[\"name\"], 'memory': row[\"memory\"]} for index, row in gpu_info.iterrows()] \n",
        "else: \n",
        "  session_info[f'gpus'] = []\n",
        "session_info['time_start'] = time.strftime(\"%H:%M:%S\", time.localtime())\n",
        "session_info['experiment_name'] = experiment_name\n",
        "session_info"
      ],
      "metadata": {
        "id": "wB28y5xMNuTp"
      },
      "id": "wB28y5xMNuTp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LcHZZFnkOLm"
      },
      "source": [
        "#Data Preprocessing\n",
        "\n",
        "##Expected Input Format\n",
        "\n",
        "At this point, we expect to have six files already loaded in the current session (by drag and drop):\n",
        "\n",
        "*   \"/content/*_CORPUS.json\" : document id and document string\n",
        "*   \"/content/*_REL.txt\": details about the relation (e.g., arg1 id, arg2 id, relation label, etc.) separated by \"/t\"\n",
        "*   \"/content/*_ANN.txt\": details about the annotation (e.g., start index, end index, value, tag label, etc.) separated by \"/t\"\n",
        "\n",
        "(* = \"train\", \"test\", \"dev\")\n",
        "\n",
        "\n",
        "##Desired Data Format\n",
        "\n",
        "Data Format Example\n",
        "\n",
        "```python\n",
        "{'guid': 'document_00000',\n",
        " 'sentence': 'I polimorfismi a singolo nucleotide del gene HNF4alpha sono associati alla conversione in diabete mellito di tipo 2.',\n",
        " 'subject_entity': {'word': 'HNF4alpha',\n",
        "                    'start_idx': 45,\n",
        "                    'end_idx': 54,\n",
        "                    'type': 'GENEORGENEPRODUCT'},\n",
        " 'object_entity': {'word': 'diabete mellito di tipo 2',\n",
        "                   'start_idx': 90,\n",
        "                   'end_idx': 115,\n",
        "                   'type': 'DISEASEORPHENOTYPICFEATURE'},\n",
        "  'label': 1,\n",
        "  'source': 'wikipedia'}\n",
        "\n",
        "```\n",
        "\n",
        "Related Labels Example\n",
        "\n",
        "```python\n",
        "{0:\"No Relation\",\n",
        " 1:\"Association\",\n",
        " 2:\"Positive Correlation\",\n",
        " 3:\"Negative Correlation\"}\n",
        "```"
      ],
      "id": "5LcHZZFnkOLm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjn33tltN5-P"
      },
      "source": [
        "## Dataset Preparation"
      ],
      "id": "kjn33tltN5-P"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z33-4G-IN-h-"
      },
      "source": [
        "Indices wrong after translation, we must recompute them.\n",
        "To recompute the correct index, we start looking for an exact match in close proximity to the 'old' indices, expanding the search window if the attempt fails. The closest correspondence we get defines the new start and end indices. If no correspondence is found, the example will be dropped."
      ],
      "id": "z33-4G-IN-h-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xS7OvCBdSL3"
      },
      "outputs": [],
      "source": [
        "def recompute_indices(sentence, match, start, end, window = 20):\n",
        "  idx=-1\n",
        "  while idx==-1:\n",
        "    newstart = start-window if (start-window)>=0 else 0\n",
        "    newend = end+window if (end+window)<len(sentence) else len(sentence)\n",
        "    substring = sentence[newstart:newend]\n",
        "    idx = substring.find(match)\n",
        "    window = window+window\n",
        "    # If the window has been extended to the whole document and no match has been found, return -1,-1\n",
        "    if newstart==0 and newend==len(sentence) and idx==-1: \n",
        "      return -1,-1\n",
        "  return newstart+idx,newstart+idx+len(match)-1"
      ],
      "id": "3xS7OvCBdSL3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bektsoMDODOV"
      },
      "source": [
        "We generate the final dictionary in the requested format, addressing all the errors that the translation process may have introduced, namely:\n",
        "\n",
        "\n",
        "*   No correct indices found for a given annotation\n",
        "*   Relation pointing to a non-existing document\n",
        "*   The entity id does not exist in the document indicated by the relation\n",
        "\n",
        "If the same relationship occurs multiple time, i.e, the same two ann1-ann2 ids appears multiple times in the annotation list for the same document,we add a different entry for each relationship in the final dataset. \n",
        "We don't combine each occurrence of ann1 with each occurence of ann2, but we create ann1-ann2 couples according to the closest correspondence in the text."
      ],
      "id": "bektsoMDODOV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5go0i8yTH5Wy"
      },
      "outputs": [],
      "source": [
        "import pdb\n",
        "import warnings\n",
        "\n",
        "def get_final_dict(sentence, a1, a2, label):\n",
        "  #If entities are NaN, drop\n",
        "  if pd.isna(a1[\"text\"]) or pd.isna(a2[\"text\"]):\n",
        "    warnings.warn(f\"Example dropped: NaN entity\")\n",
        "    return None\n",
        "\n",
        "  idx1 = recompute_indices(sentence,a1[\"text\"],a1[\"start\"],a1[\"end\"])\n",
        "  idx2 = recompute_indices(sentence,a2[\"text\"],a2[\"start\"],a2[\"end\"])\n",
        "\n",
        "  if idx1[0]==-1 or idx2[0]==-1:\n",
        "    warnings.warn(f\"Example dropped: impossible to recompute the correct indices\")\n",
        "    return None\n",
        "    \n",
        "  return {'guid': id, 'sentence': sentence,\n",
        "          'subject_entity': {'word': a1[\"text\"],\n",
        "                            'start_idx': idx1[0],\n",
        "                            'end_idx': idx1[1],\n",
        "                            'type': a1[\"type\"]},\n",
        "          'object_entity': {'word': a2[\"text\"],\n",
        "                            'start_idx': idx2[0],\n",
        "                            'end_idx': idx2[1],\n",
        "                            'type': a2[\"type\"]},\n",
        "          'label': label,\n",
        "          'source': 'BioRED'}\n",
        "\n",
        "def format_inputs(df_rel, df_ann, df_corpus, label_mapping):\n",
        "    formatted_inputs = []\n",
        "    drop_count = 0\n",
        "\n",
        "    for i in tqdm(range(df_rel.shape[0])):\n",
        "      #Relation Info\n",
        "      rel = df_rel.iloc[i]\n",
        "      label = rel[\"relation\"]\n",
        "      id = rel[\"pmid\"]\n",
        "\n",
        "      #Corpus Info\n",
        "      #if the relation points to a document that does not extist, drop\n",
        "      if len(df_corpus.loc[df_corpus[\"PMID\"]==str(id)][\"Testo\"])==0:\n",
        "        warnings.warn(f\"Example dropped: relation points to non-existing document (pmid: {str(id)})\")\n",
        "        drop_count+=1\n",
        "        continue\n",
        "      sentence = df_corpus.loc[df_corpus[\"PMID\"]==str(id)][\"Testo\"].iloc[0]\n",
        "\n",
        "      #Entities Info\n",
        "      arg1_id = rel[\"arg1_id\"].replace(\"Arg1:\", \"\")\n",
        "      arg2_id = rel[\"arg2_id\"].replace(\"Arg2:\", \"\")\n",
        "      ann1 = df_ann.loc[(df_ann['pmid'] == rel[\"pmid\"]) & (df_ann['entity_id'] == arg1_id)]\n",
        "      ann2 = df_ann.loc[(df_ann['pmid'] == rel[\"pmid\"]) & (df_ann['entity_id'] == arg2_id)]\n",
        "\n",
        "      #If no match, one of the arguments does not exists anymore (probably dropped during auto-translation of the dataset)\n",
        "      #In this case, skip this relation and increment drop count\n",
        "      if ann1.shape[0]==0:\n",
        "        #warnings.warn(f\"Example dropped: entity id {arg1_id} does not exist in document {id}\")\n",
        "        drop_count +=1\n",
        "        continue\n",
        "      elif ann2.shape[0]==0:\n",
        "        #warnings.warn(f\"Example dropped: entity id {arg2_id} does not exist in document {id}\")\n",
        "        drop_count +=1\n",
        "        continue\n",
        "\n",
        "      #If the same relationship occurs multiple time, i.e, the same two ann1-ann2 ids appears multiple times in the annotation list for the same document,\n",
        "      #we add a different row for each relationship in the final dataset. We don't combine each occurrence of ann1 with each occurence of ann2, but we create ann1-ann2 \n",
        "      #couples according to the closest correspondence in the text\n",
        "\n",
        "      #we might have more occurences of ann1 then ann2 or vice-versa, therefore we must define two different loops based on which of the two sets is larger\n",
        "      success = False\n",
        "      if ann1.shape[0]>ann2.shape[0]:\n",
        "        for j in range(ann1.shape[0]):\n",
        "          a1 = ann1.iloc[j]\n",
        "          diff = ann2['start']-a1['end']\n",
        "          valid_idx = np.where(diff > 0)[0]\n",
        "          if len(valid_idx)==0: continue \n",
        "          idx = valid_idx[diff.iloc[valid_idx].argmin()]       \n",
        "          a2 = ann2.iloc[idx]\n",
        "          formatted_input = get_final_dict(sentence,a1,a2,label_mapping[label])\n",
        "          if formatted_input is not None:\n",
        "            formatted_inputs.append(formatted_input)\n",
        "            success = True\n",
        "      else:\n",
        "        for j in range(ann2.shape[0]):\n",
        "          a2 = ann2.iloc[j]\n",
        "          diff = ann1['end']-a2['start']\n",
        "          valid_idx = np.where(diff < 0)[0]\n",
        "          if len(valid_idx)==0: continue             \n",
        "          idx = valid_idx[diff.iloc[valid_idx].argmax()]         \n",
        "          a1 = ann1.iloc[idx]\n",
        "          formatted_input = get_final_dict(sentence,a1,a2,label_mapping[label])\n",
        "          if formatted_input is not None:\n",
        "            formatted_inputs.append(formatted_input)\n",
        "            success = True\n",
        "        \n",
        "      #If we don't manage to generate any new entry from the ann1-ann2 couples, consider this iteration as failed and increment the drop count\n",
        "      #We don't have to trigger a new warning because they have already been triggered in the get_final_dict function\n",
        "      if not success:\n",
        "        drop_count +=1\n",
        "        continue\n",
        "    print(f\"\\ndropped: {round(100*drop_count/i,2)}%\")\n",
        "    return(formatted_inputs)"
      ],
      "id": "5go0i8yTH5Wy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mb0NKEeh0c6X"
      },
      "outputs": [],
      "source": [
        "formatted_datasets = {\n",
        "    \"train\":[],\n",
        "    \"test\":[],\n",
        "    \"dev\":[]\n",
        "}\n",
        "\n",
        "#CHEMPROT\n",
        "colnames = {\"rel\":[\"pmid\",\"cpr\",\"eval_type\",\"relation\",\"arg1_id\",\"arg2_id\"],\n",
        "            \"ann\":[\"pmid\",\"entity_id\",\"start\",\"end\",\"text\",\"type\"]}\n",
        "#BIORED\n",
        "#colnames = {\"rel\":[\"pmid\",\"relation\",\"arg1_id\",\"arg2_id\",\"novel\"],\n",
        "#            \"ann\":[\"pmid\",\"start\",\"end\",\"text\",\"type\",\"entity_id\"]}\n",
        "\n",
        "\n",
        "#Label Mapping using \n",
        "df_rel = pd.read_csv(\"train_REL.txt\", sep='\\t',names=colnames[\"rel\"], header=None)\n",
        "\n",
        "#map label strings to integers and vice versa\n",
        "labels = np.unique(df_rel[[\"relation\"]])\n",
        "num_to_labels = dict(zip([i for i in range(len(labels))],labels)) \n",
        "labels_to_num = {v: k for k, v in num_to_labels.items()}\n",
        "\n",
        "for key in formatted_datasets.keys():\n",
        "  #REL DATAFRAME\n",
        "  df_rel = pd.read_csv(key+\"_REL.txt\", sep='\\t',names=colnames[\"rel\"], header=None)\n",
        "\n",
        "  #ANN DATAFRAME\n",
        "  df_ann = pd.read_csv(key+\"_ANN.txt\", sep='\\t', names=colnames[\"ann\"], header=None)\n",
        "\n",
        "  #CORPUS DATAFRAME\n",
        "  f = open(key+\"_CORPUS.json\", encoding='utf-8')\n",
        "  df_corpus = pd.DataFrame(json.load(f)[\"data\"])\n",
        "  # Closing file\n",
        "  f.close()\n",
        "\n",
        "  formatted_datasets[key] = format_inputs(df_rel, df_ann, df_corpus, labels_to_num)"
      ],
      "id": "mb0NKEeh0c6X"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9Na50PFqk4Q"
      },
      "source": [
        "Check correspondence between label nums and label strings + the numerosity of each label in the training set"
      ],
      "id": "k9Na50PFqk4Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "compact-serial"
      },
      "outputs": [],
      "source": [
        "label_count = {}\n",
        "for data in formatted_datasets[\"train\"]:\n",
        "    label = str(data['label'])+\") \"+num_to_labels[data['label']]\n",
        "    if label not in label_count:\n",
        "        label_count[label] = 1\n",
        "    else:\n",
        "        label_count[label] += 1\n",
        "\n",
        "label_count = dict(sorted(label_count.items(), key=lambda x: x[0]))\n",
        "label_count"
      ],
      "id": "compact-serial"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "starting-boating"
      },
      "source": [
        "Add special tokens <subj> e <obj> to tag the sentence with the correspondent annotation 1 and annotation 2 of the relation\n",
        "\n",
        "For instance, this entry\n",
        "\n",
        "```python\n",
        "{'guid': 'document_00000',\n",
        " 'sentence': 'I polimorfismi a singolo nucleotide del gene HNF4alpha sono associati alla conversione in diabete mellito di tipo 2.',\n",
        " 'subject_entity': {'word': 'HNF4alpha',\n",
        "                    'start_idx': 45,\n",
        "                    'end_idx': 54,\n",
        "                    'type': 'GENEORGENEPRODUCT'},\n",
        " 'object_entity': {'word': 'diabete mellito di tipo 2',\n",
        "                   'start_idx': 90,\n",
        "                   'end_idx': 115,\n",
        "                   'type': 'DISEASEORPHENOTYPICFEATURE'},\n",
        "  'label': 1,\n",
        "  'source': 'wikipedia'}\n",
        "\n",
        "```\n",
        "\n",
        "becomes this:\n",
        "\n",
        "\n",
        "```python\n",
        "'I polimorfismi a singolo nucleotide del gene <subj>HNF4alpha</subj> sono associati alla conversione in <obj>diabete mellito di tipo 2</obj>.'\n",
        "```\n"
      ],
      "id": "starting-boating"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "directed-direction"
      },
      "outputs": [],
      "source": [
        "def add_entity_tokens(sentence, object_entity, subject_entity):\n",
        "    obj_start_idx, obj_end_idx = object_entity['start_idx'], object_entity['end_idx']\n",
        "    subj_start_idx, subj_end_idx = subject_entity['start_idx'], subject_entity['end_idx']\n",
        "    \n",
        "    if obj_start_idx < subj_start_idx:\n",
        "        new_sentence = sentence[:obj_start_idx] + '<obj>' + sentence[obj_start_idx:obj_end_idx+1] + '</obj>' + \\\n",
        "                       sentence[obj_end_idx+1:subj_start_idx] + '<subj>' + sentence[subj_start_idx:subj_end_idx+1] + \\\n",
        "                       '</subj>' + sentence[subj_end_idx+1:]\n",
        "    else:\n",
        "        new_sentence = sentence[:subj_start_idx] + '<subj>' + sentence[subj_start_idx:subj_end_idx+1] + '</subj>' + \\\n",
        "                       sentence[subj_end_idx+1:obj_start_idx] + '<obj>' + sentence[obj_start_idx:obj_end_idx+1] + \\\n",
        "                       '</obj>' + sentence[obj_end_idx+1:]\n",
        "    \n",
        "    return new_sentence\n",
        "\n",
        "def parse_re_dataset(dataset):\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    \n",
        "    for data in dataset:\n",
        "        sentence = add_entity_tokens(data['sentence'], data['object_entity'], data['subject_entity'])\n",
        "        sentences.append(sentence)\n",
        "        labels.append(data['label'])\n",
        "\n",
        "    ds = Dataset.from_pandas(pd.DataFrame({'text': sentences,'label': labels}))\n",
        "\n",
        "    return ds"
      ],
      "id": "directed-direction"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "valuable-nightmare"
      },
      "outputs": [],
      "source": [
        "train_ds = parse_re_dataset(formatted_datasets[\"train\"])\n",
        "dev_ds = parse_re_dataset(formatted_datasets[\"dev\"])\n",
        "test_ds = parse_re_dataset(formatted_datasets[\"test\"])"
      ],
      "id": "valuable-nightmare"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqEDNQmHHDVw"
      },
      "outputs": [],
      "source": [
        "train_ds[2]"
      ],
      "id": "XqEDNQmHHDVw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuclear-thomas"
      },
      "source": [
        "# Training\n",
        "\n",
        "The task consists in calssifying N different types of relations. To do so, we create a classification model that uses the [CLS] token to output the most probable class between N passing it through a linear layer with output dimension N.\n",
        "\n",
        "![Imgur](https://i.imgur.com/qaUObkV.png)\n"
      ],
      "id": "nuclear-thomas"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05xPyYM8P0ki"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "id": "05xPyYM8P0ki"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "minus-leisure"
      },
      "outputs": [],
      "source": [
        "model_checkpoints = [\n",
        "                     #\"dbmdz/bert-base-italian-xxl-cased\",\n",
        "                     #\"/content/gdrive/MyDrive/Colab Environments/biobert_models/bio-full\",\n",
        "                     \"/content/gdrive/MyDrive/Colab Environments/biobert_models/med-reg-v3\",\n",
        "                     #\"/content/gdrive/MyDrive/Colab Environments/biobert_models/med-reg-v12\",\n",
        "                     #\"/content/gdrive/MyDrive/Colab Environments/biobert_models/med-reg-v3-enriched\"\n",
        "                    ]\n",
        "\n",
        "seeds = [\n",
        "         #3407, \n",
        "         #6, \n",
        "         11, \n",
        "         61,\n",
        "         1\n",
        "        ]\n",
        "\n",
        "#This can be changed according to the downstream dataset. The only important thing is that they remain consistent for *ALL* the models   \n",
        "batch_size = 16\n",
        "learning_rate = 3e-5\n",
        "epochs=7\n",
        "weight_decay=0.01"
      ],
      "id": "minus-leisure"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsRzsKAqCYFr"
      },
      "source": [
        "## Preprocessing functions"
      ],
      "id": "JsRzsKAqCYFr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eU9lF9toASCD"
      },
      "outputs": [],
      "source": [
        "def prepare_tokenizer(model_name):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "  # Bisogna aggiungere gli special tokens per far capire al modello che non devono essere trattati come testo normale della sequenza\n",
        "  entity_special_tokens = {'additional_special_tokens': ['<obj>', '</obj>', '<subj>', '</subj>']}\n",
        "  num_additional_special_tokens = tokenizer.add_special_tokens(entity_special_tokens)\n",
        "  return tokenizer\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)"
      ],
      "id": "eU9lF9toASCD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lhb0WSnX_uZK"
      },
      "source": [
        "## Metrics"
      ],
      "id": "Lhb0WSnX_uZK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdhNsovuiHjy"
      },
      "outputs": [],
      "source": [
        "m_calc = {\n",
        "    \"precision\":evaluate.load(\"precision\"),\n",
        "    \"recall\":evaluate.load(\"recall\"),\n",
        "    \"accuracy\":evaluate.load(\"accuracy\"),\n",
        "    \"f1\":evaluate.load(\"f1\")\n",
        "}\n",
        "def compute_metrics(p):\n",
        "  logits, labels = p\n",
        "  predictions = np.argmax(logits, axis=1)\n",
        "  return {'acc': m_calc[\"accuracy\"].compute(references=labels, predictions=predictions)[\"accuracy\"],\n",
        "          'prec': m_calc[\"precision\"].compute(references=labels, predictions=predictions, average=\"weighted\")[\"precision\"],\n",
        "          'recall': m_calc[\"recall\"].compute(references=labels, predictions=predictions, average=\"weighted\")[\"recall\"],\n",
        "          'f1': m_calc[\"f1\"].compute(references=labels, predictions=predictions, average=\"weighted\")[\"f1\"]}"
      ],
      "id": "LdhNsovuiHjy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C7Dkpn6_wRK"
      },
      "source": [
        "## Training Loop"
      ],
      "id": "-C7Dkpn6_wRK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aue6XswvBXXC"
      },
      "outputs": [],
      "source": [
        "for model_checkpoint in model_checkpoints:\n",
        "  results_collector = []\n",
        "  for seed in seeds:\n",
        "    # Seed must be set before creating the model, otherwise the random head will be initialized in a different way every time and the results will not be replicable\n",
        "    # From now on, the seed is set for *all* the random processes, including numpy, sklearn, etc...not only for transformers!\n",
        "    set_seed(seed)\n",
        "\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = prepare_tokenizer(model_checkpoint)\n",
        "\n",
        "    # Initialize the TokenClassification transformer with checkpoint weights            \n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=len(label_count))\n",
        "    \n",
        "    # Load del modello. Abbiamo aggiunto 4 tokens, anche se speciali, quindi bisogna ridimensionare i layers di BERT aggiungendo 4, quindi 32000-->32004\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "    # Processa gli input e mettili in formato compatibile con il modello\n",
        "    train_dataset = train_ds.map(preprocess_function, batched=True)\n",
        "    test_dataset = test_ds.map(preprocess_function, batched=True)\n",
        "    dev_dataset = dev_ds.map(preprocess_function, batched=True)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"/content/{os.path.basename(model_checkpoint)}_ft_RE/{seed}\",           \n",
        "        evaluation_strategy=\"epoch\",\n",
        "        logging_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        save_total_limit=3,\n",
        "        load_best_model_at_end = True,\n",
        "        metric_for_best_model = \"f1\",\n",
        "        learning_rate=learning_rate,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        num_train_epochs=epochs,\n",
        "        weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=dev_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics = compute_metrics,\n",
        "        callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    predictions,label_ids, metrics  = trainer.predict(test_dataset)\n",
        "    print(metrics)\n",
        "    metrics[\"seed\"]=seed\n",
        "    results_collector.append(metrics)\n",
        "\n",
        "  df_results = pd.DataFrame(results_collector)\n",
        "  display(df_results)\n",
        "  df_results.to_csv(f'/content/RE_results_{os.path.basename(model_checkpoint)}.csv')\n",
        "  files.download(f'/content/RE_results_{os.path.basename(model_checkpoint)}.csv')"
      ],
      "id": "aue6XswvBXXC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalize session info and download"
      ],
      "metadata": {
        "id": "DgwaQ7uITFXH"
      },
      "id": "DgwaQ7uITFXH"
    },
    {
      "cell_type": "code",
      "source": [
        "session_info['checkpoints'] = [os.path.basename(c) for c in model_checkpoints]\n",
        "session_info['seeds'] = seeds\n",
        "session_info['training_arguments'] = training_args.to_dict()\n",
        "session_info['time_end'] = time.strftime(\"%H:%M:%S\", time.localtime())\n",
        "\n",
        "with open(f'/content/session_info.json', \"w\") as outfile:\n",
        "    outfile.write(json.dumps(session_info, indent=4))\n",
        "files.download(f'/content/session_info.json')"
      ],
      "metadata": {
        "id": "NNNE8WGBR7m3"
      },
      "execution_count": null,
      "outputs": [],
      "id": "NNNE8WGBR7m3"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
