{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IVN-RIN/bio-med-BIT/blob/main/notebooks/BioBIT_Language_Modeling_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BioBIT <u>Language Modeling</u> Evaluation**\n",
        "\n",
        "*Tommaso M Buonocore, University of Pavia, 2022*\n",
        "\n",
        "*Last edited: 05/12/2022*\n",
        "\n",
        "*Related paper: [Localising In-Domain Adaptation of Transformer-Based Biomedical Language Models](https://www.medrxiv.org/content/XXXXXX)*\n",
        "\n",
        "---\n",
        "\n",
        "This notebook contains some tests carried out on the **BioBIT** and **MedBIT** models regarding the *Masked Language Modelling* (MLM) task, which consists in partially masking the model input text and verifying whether it is able to correctly predict the missing portions of the sequence.\n",
        "\n",
        "The tests are carried out using the 'fill_mask' method of HuggingFace, which does not support the replacement of more than one token for each input. This means, that if you mask the word \"asma\", which is actually represented in BERT as two tokens, \"\\[as, ##ma\\]\", the expected result is \"as\", not \"asma\"."
      ],
      "metadata": {
        "id": "M89uH15xtMiB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Init\n"
      ],
      "metadata": {
        "id": "Yw1VXjLp06dQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip3 install datasets transformers seqeval\n",
        "from transformers import pipeline,AutoModel, AutoTokenizer, AutoModelForMaskedLM, logging\n",
        "from datasets import load_metric"
      ],
      "metadata": {
        "id": "QomwRP8ZQ07G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Imports"
      ],
      "metadata": {
        "id": "EJnTziKDOfAQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHq7aCPMOHrv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from random import sample\n",
        "import math \n",
        "import json\n",
        "import string\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We rely upon google drive for file management"
      ],
      "metadata": {
        "id": "Bi4dtGPk4dhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "models_path = 'your/path/biobert_models'\n",
        "os.chdir('gdrive/MyDrive/'+models_path)"
      ],
      "metadata": {
        "id": "e3anpQO1Cvrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.set_verbosity_error() # reduce verbosity"
      ],
      "metadata": {
        "id": "eLhRDSwBfTL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoints = {'baseBIT':'dbmdz/bert-base-italian-xxl-cased',\n",
        "               'bioBIT_xs':'bio-tiny', \n",
        "               'bioBIT_s':'bio-small', \n",
        "               'bioBIT_m':'bio-medium', \n",
        "               'bioBIT_l':'bmi-labmedinfo/bioBIT', \n",
        "               #'medBIT_OR':'med-reg-original',\n",
        "               #'medBIT':'bmi-labmedinfo/medBIT',\n",
        "               #'medBIT_r0':'med-reg-v0',\n",
        "               #'medBIT_r1':'med-reg-v1',\n",
        "               #'medBIT_r2':'med-reg-v2',\n",
        "               #'medBIT_r3':'med-reg-v3',\n",
        "               #'medBIT_rf':'med-frozen',\n",
        "               #'medBIT_r3f':'med-reg-v3-clean-fixed-10',\n",
        "               #'medBIT_r3+':'bmi-labmedinfo/medBIT-r3-plus',\n",
        "               #'medBIT_r12+':'med-reg-v12'\n",
        "               } \n",
        "\n",
        "tokenizers = {}\n",
        "for k,v in checkpoints.items():\n",
        "  tokenizers[k] = AutoTokenizer.from_pretrained(v, truncation=True)"
      ],
      "metadata": {
        "id": "jcrK9TXz-JRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilities"
      ],
      "metadata": {
        "id": "4J_Kt1AmOjKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate MLM of model on a list of sentences\n",
        "def evaluate_mlm(model, tokenizer, masked_sentences, top_k = 5, print_progression = True):\n",
        "    # Define pipeline\n",
        "    fill_mask = pipeline(\n",
        "      task='fill-mask',\n",
        "      model=model,\n",
        "      tokenizer=tokenizer,\n",
        "      top_k=top_k\n",
        "    )\n",
        "    # Apply pipeline to every sentence\n",
        "    if print_progression:\n",
        "      results = [fill_mask(el) for el in tqdm(masked_sentences, position=0, leave=True)]\n",
        "    else:\n",
        "      results = [fill_mask(el) for el in masked_sentences]\n",
        "    return results"
      ],
      "metadata": {
        "id": "vd4-KB_vOnm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get value of [MASK] in masked sentence\n",
        "def get_masked_word(original_sentences, masked_sentences):\n",
        "    masked = []\n",
        "    exclude = set(string.punctuation)\n",
        "    for i, el in enumerate(masked_sentences):\n",
        "        begin = el.find('[MASK]')\n",
        "        end = begin+original_sentences[i][begin:].find(' ') # Look for first white space after begin of masked word\n",
        "        if end<begin:\n",
        "            end = begin+original_sentences[i][begin:].find('.') # Look for first period after begin of masked word\n",
        "        token = original_sentences[i][begin:end]\n",
        "        token = ''.join(ch for ch in token if ch not in exclude) # Remove punctuation\n",
        "        masked.append(token)\n",
        "    return masked"
      ],
      "metadata": {
        "id": "80fcm6FxOnUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print results of MLM in a convenient way\n",
        "def get_results(results, original_sentences, masked_sentences, tokenizer, verbose=True):\n",
        "    refs = get_masked_word(original_sentences, masked_sentences)\n",
        "    scores = [0]*len(refs)\n",
        "    for i, sentence in enumerate(results):\n",
        "        if verbose: print(f\"\"\"------------------- Sentence #{i+1} -------------------\\nMasked sentence = {masked_sentences[i]}\\nContext size = {len(tokenizer(original_sentences[i])['input_ids'])} tokens\\nTarget = {refs[i]}\\nPredicted:\\n\"\"\")\n",
        "        for j,el in enumerate(sentence):\n",
        "            if refs[i].lower()==el['token_str'].lower():\n",
        "              scores[i]=round(1/(j+1),2)\n",
        "            if verbose: print(f\"{j+1}) {el['token_str']} [{(el['score']*100):.2f}]\")\n",
        "    mlm_score = sum(scores)/len(scores)\n",
        "    if verbose: print(f\"\"\"\\nMLM score = {mlm_score:.2f}\\n-- score details: {scores}\\n\"\"\")\n",
        "    return {'avg':mlm_score,'scores':scores}"
      ],
      "metadata": {
        "id": "TY3pvtrkOndP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataframe(checkpoints, tokenizers, original_sentences, masked_sentences, top_k=5, verbose = False):\n",
        "  targets = get_masked_word(original_sentences, masked_sentences)\n",
        "  columns = ['avg_score']+targets\n",
        "  df = pd.DataFrame(columns=columns, index = checkpoints.keys())\n",
        "  for k,v in checkpoints.items():\n",
        "    r = evaluate_mlm(v, tokenizers[k], masked_sentences, top_k=top_k)\n",
        "    s = get_results(r, original_sentences, masked_sentences, tokenizers[k], verbose=verbose)\n",
        "    row = [s['avg']]+s['scores']\n",
        "    df.loc[k]=row\n",
        "  return(df)"
      ],
      "metadata": {
        "id": "v9mKLmYTfX8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLM test on biomedical concepts\n",
        "\n",
        "This test evaluates the lexical comprehension of the language models, focusing on biomedical concepts. The masked words are mainly nouns related to the biomedical field that can be understood by looking at the sorrounding context.\n",
        "\n",
        "Sentences have different lenghts and belong to different categories.\n",
        "\n",
        "Input data format:\n",
        "\n",
        "```json\n",
        "data: [\n",
        "    {\n",
        "      \"source\": url,\n",
        "      \"type\": category,\n",
        "      \"original\": original sentence,\n",
        "      \"masked\": [\"masked sentence 1\", \"masked sentence 2\", \"...\"]\n",
        "    },\n",
        "    {..},\n",
        "    {..}\n",
        "]\n",
        "```"
      ],
      "metadata": {
        "id": "MV5lOeaGNq47"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load MLM dataset"
      ],
      "metadata": {
        "id": "kEFuMHDeMIOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"/content/mlm_data.json\", encoding=\"utf-8\")\n",
        "json_data = json.load(f)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "xM8fPITq-wY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = json_data[\"data\"]\n",
        "#uncomment next line for downsampling\n",
        "#sentences = [sentences[i] for i in sample(range(len(json_data[\"data\"])),10)]\n",
        "masked_count = sum([len(sentence[\"masked\"]) for sentence in sentences])\n",
        "num_tok = [len(t) for t in tokenizers[list(tokenizers.keys())[0]]([sentence[\"original\"] for sentence in sentences])['input_ids']]\n",
        "\n",
        "print(f\"Original sentences: {len(sentences)}\")\n",
        "print(f\"Masked sentences: {masked_count}\")\n",
        "print(f\"Sentence length: {min(num_tok)}-{max(num_tok)} tokens (avg: {np.mean(num_tok):.0f})\")"
      ],
      "metadata": {
        "id": "6H60jAEk9OZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Categories Distribution"
      ],
      "metadata": {
        "id": "ZNAEbLBpDAcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# categories are collected in Italian, build a it2en dict to get the english version\n",
        "cat_it2en = {\"Allergologia\":\"Allergy\",\"Altro\":\"Other\",\"Bioetica\":\"Bioethics\",\"Biologia Cellulare\":\"Cell Biology\",\"Cardiologia\":\"Cardiology\",\"Chirurgia\":\"Surgery\",\"Diabetologia\":\"Diabetology\",\"Ematologia\":\"Hematology\",\"Endocrinologia\":\"Endocrinology\",\"Epidemiologia\":\"Epidemiology\",\"Farmacologia\":\"Pharmacology\",\"Fisiologia\":\"Physiology\",\"Malattie Rare\":\"Rare Diseases\",\"Nefrologia\":\"Nephrology\",\"Neurologia\":\"Neurology\",\"Odontoiatria\":\"Dentistry\",\"Oncologia\":\"Oncology\",\"Ortopedia\":\"Orthopedics\",\"Pediatria\":\"Pediatrics\",\"Pneumologia\":\"Pneumology\",\"Psichiatria\":\"Psychiatry\",\"Radiologia\":\"Radiology\"}\n",
        "# textbooks categories have been identified and collected manually\n",
        "textbooks_cat = {\"Allergologia\":1, \"Altro\":45, \"Bioetica\":5,\"Biologia Cellulare\":2, \"Cardiologia\":4,\"Chirurgia\":4,\"Diabetologia\":0,\"Ematologia\":4,\"Endocrinologia\":0,\"Epidemiologia\":1,\"Farmacologia\":14,\"Fisiologia\":6,\"Malattie Rare\":1,\"Nefrologia\":1,\"Neurologia\":10,\"Odontoiatria\":3,\"Oncologia\":5,\"Ortopedia\":4,\"Pediatria\":5,\"Pneumologia\":5,\"Psichiatria\":21,\"Radiologia\":8}\n",
        "\n",
        "textbooks_cat_fig = sum([[cat_it2en[k]]*v for k,v in textbooks_cat.items()],[])\n",
        "mlm_cat_fig = sum([[cat_it2en[sentence[\"type\"]]]*len(sentence[\"masked\"]) for sentence in sentences],[])\n",
        "\n",
        "#plot\n",
        "font = {'size'   : 18}\n",
        "plt.rc('font', **font)\n",
        "fig, ax = plt.subplots(figsize=(18, 8))\n",
        "ax.tick_params(axis='x', rotation=90)\n",
        "ax.set_xlabel('\\nCategory')\n",
        "ax.set_ylabel('% Total')\n",
        "plt.hist([sorted(mlm_cat_fig), sorted(textbooks_cat_fig)], density=True, bins = np.arange(len(set(mlm_cat_fig))+1)-0.5)\n",
        "ax.legend(loc='upper right', labels=['MLM Dataset', 'Textbooks Corpus'])\n",
        "plt.savefig('/content/mlm_data_cat_distribution.png')"
      ],
      "metadata": {
        "id": "n4zabdnEFt_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "XEPY4dbVe0BL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: ```[MASK]``` replacement is token-based. If you mask a word that is represented by WordPiece as a sequence of multiple tokens, you'll get unexpected results.\n",
        "\n",
        "example:\n",
        "\n",
        "```\n",
        "INPUT: \"L'[MASK] è una condizione in cui le vie respiratorie si restringono e si gonfiano.\" \n",
        "(EN: \"[MASK] is a condition in which your airways narrow and swell.\"])\n",
        "\n",
        "MASKED WORD: \"asma\" (EN: \"asthma\")\n",
        "\n",
        "EXPECTED OUTPUT: \"asma\"\n",
        "ACTUAL OUPTUT: \"as\"\n",
        "\n",
        "CORRECT = False\n",
        "```\n",
        "\n",
        "This happens because \"asma\" is tokenized as ```[\"as\",\"##ma\"]```, and the model replaces [MASK] with a single token while we are masking a whole multi-token word.\n"
      ],
      "metadata": {
        "id": "L5v9URm17JAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizers['bio-full'].convert_ids_to_tokens(tokenizers['bio-full'](\"asma\")[\"input_ids\"])"
      ],
      "metadata": {
        "id": "1d4eZ92CmEB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collect the results for each model checkpoint and save everything into a dataframe."
      ],
      "metadata": {
        "id": "Nqyo0Rip9GCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#warning: it takes approx 10 mins for each model on a CPU (1s/it worst case)\n",
        "original_sentences = sum([[sentence[\"original\"]]*len(sentence[\"masked\"]) for sentence in sentences],[])\n",
        "masked_sentences = sum([sentence[\"masked\"] for sentence in sentences],[])\n",
        "df = get_dataframe(checkpoints, tokenizers, original_sentences, masked_sentences, top_k=5)\n",
        "df.T.reset_index()\n",
        "df.to_csv(\"/content/dataframeMLM.csv\")\n",
        "df"
      ],
      "metadata": {
        "id": "1jVhcJNcY33C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to test a single sentence:"
      ],
      "metadata": {
        "id": "nqX1fdi-9Mzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "masked_sentence = \"L'ipotesi più in voga è che nell’Alzheimer la regione dell’ippocampo riduca la capacità di gestire la dopamina andando a compromettere la [MASK] che è il principale sintomo della patologia.\"\n",
        "original_sentence = \"L'ipotesi più in voga è che nell’Alzheimer la regione dell’ippocampo riduca la capacità di gestire la dopamina andando a compromettere la memoria che è il principale sintomo della patologia.\"\n",
        "get_dataframe(checkpoints, tokenizers, [original_sentence], [masked_sentence], top_k=5, verbose = True)"
      ],
      "metadata": {
        "id": "D7oH2ulUIE2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of predictions are alwasy wrong or always correct for all the models.\n",
        "Now we want to focus only on those examples where the predictions changes."
      ],
      "metadata": {
        "id": "lLpXDDqVfABJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"dataframeMLM.csv\", index_col=0)\n",
        "\n",
        "df =df.drop([\"medBIT_ro\",\"medBIT_s\",\"medBIT_r3\"],axis=0)\n",
        "\n",
        "df_fig = df.drop(\"avg_score\",axis=1).T\n",
        "df_fig = df_fig.astype(float)\n",
        "print(f\"Never-predicted entries: {100*len(df_fig[(df_fig == 0).all(1)])/df.shape[1]:.1f}%\")\n",
        "print(f\"Always-correct predictions: {100*len(df_fig[(df_fig == 1).all(1)])/df.shape[1]:.1f}%\")\n",
        "df_fig = df_fig[(df_fig != 0).any(1)] #remove the always-zero rows\n",
        "df_fig = df_fig[(df_fig != 1).any(1)] #remove the always-one rows\n",
        "print(f\"Changing predictions: {100*len(df_fig)/df.shape[1]:.1f}%\")\n",
        "df_fig.to_csv(\"/content/dataframeMLM_filtered.csv\")"
      ],
      "metadata": {
        "id": "4fCZjVJXW7UN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Heathmap"
      ],
      "metadata": {
        "id": "i0cEOPPmpaCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "newcmp = ListedColormap(plt.get_cmap(\"Blues\",100)([0]*19+[15]*5+[30]*8+[45]*17+[60]*50+[75]*1))\n",
        "plt.figure(figsize=(6, 46))\n",
        "plt.tick_params(axis='both', which='major', labelsize=10, labelbottom = False, bottom=False, top = False, labeltop=True)\n",
        "ax = sns.heatmap(df_fig, linewidths=.5, cmap = newcmp, cbar = False)\n",
        "plt.savefig('/content/heatmapMLM.png')\n",
        "plt.show()\n",
        "print(f\"\\nAverage Score:\\n{round((df_fig.sum(axis=0))/len(df_fig),2)}\")\n",
        "print(f\"size: {len(df_fig)}\")"
      ],
      "metadata": {
        "id": "1VKKfT-DVvAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_rank_progression(word):\n",
        "  #if more than one appearance of the same word, average\n",
        "  df_selection = df_fig.loc[word] if len(df_fig.loc[word].shape)<=1 else df_fig.loc[word].mean(axis=0)\n",
        "  \n",
        "  g = sns.relplot(\n",
        "      data=df_selection, kind=\"line\"  #change range if you want to include more/less models\n",
        "  )\n",
        "  (g.set_axis_labels(\"\\n\"+word.upper(), \"MRR\")\n",
        "    .set(ylim=(0, 1))\n",
        "    .set_xticklabels(rotation=90)\n",
        "    .set_titles(\"Region\")\n",
        "    .tight_layout(w_pad=0))"
      ],
      "metadata": {
        "id": "DLD-uiYGxQDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Rank Progression"
      ],
      "metadata": {
        "id": "MnPjiywW9mMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.lines import Line2D\n",
        "df_fig2 = df_fig.groupby(level=0).agg('mean')\n",
        "custom_lines = [Line2D([0], [0], color='blue',lw=4),\n",
        "                Line2D([0], [0], color='orange',lw=4)]\n",
        "fig, ax = plt.subplots(figsize=(16, 12))\n",
        "ax.tick_params(axis='x', rotation=90)\n",
        "ax.set_xlabel('Model')\n",
        "ax.set_ylabel('MRR')\n",
        "ax.legend(custom_lines, ['Single Words', 'Average'], loc=\"upper right\")\n",
        "p1 = sns.lineplot(data=df_fig2.T, ax=ax, legend=False, alpha=0.05, linestyle=\":\", palette = ['blue']*len(df_fig2))\n",
        "p2 = sns.lineplot(data=df_fig2.mean(axis=0).T, linewidth = 3, ax=ax, marker='o')\n",
        "for col in df_fig2.columns:\n",
        "  ax.annotate(round(df_fig2.mean(axis=0).T[col],2), (col,df_fig2.mean(axis=0).T[col]-0.025),color=\"orange\", ha='center')\n",
        "plt.savefig('/content/trajectoryMLM.png')"
      ],
      "metadata": {
        "id": "IYHZAQG70MZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a single word:"
      ],
      "metadata": {
        "id": "-sbAFqEz9sn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_rank_progression(\"colon\")"
      ],
      "metadata": {
        "id": "kf3i2ahjMQLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sankey Plot"
      ],
      "metadata": {
        "id": "aG3-LIKB9uMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getSankeyDataFrame(sourcename, targetname, df, label_offset = 0):\n",
        "  dfsankey = df\n",
        "  dfsankey = dfsankey.loc[[sourcename,targetname]].T\n",
        "  dfsankey = dfsankey.drop(\"avg_score\")\n",
        "  dfsankey = dfsankey.rename(columns={sourcename: \"source\", targetname: \"target\"})\n",
        "  dfsankey[\"word\"] = dfsankey.index\n",
        "  dfsankey = dfsankey.groupby(['source','target']).agg({'source':'size','word': lambda x: ', '.join(x)}).rename(columns={'source':'value'}).reset_index()\n",
        "  dfsankey = dfsankey.drop([0,dfsankey.shape[0]-1])\n",
        "  dfsankey[\"increment\"] = dfsankey[\"source\"]<=dfsankey[\"target\"]\n",
        "  dfsankey[\"source\"] = dfsankey[\"source\"].map({0.0 : 5+label_offset, 0.2 : 4+label_offset, 0.25 : 3+label_offset,  0.33 : 2+label_offset, 0.5 : 1+label_offset, 1.0 : 0+label_offset})\n",
        "  dfsankey[\"target\"] = dfsankey[\"target\"].map({0.0 : 11+label_offset, 0.2 : 10+label_offset, 0.25 : 9+label_offset,  0.33 : 8+label_offset, 0.5 : 7+label_offset, 1.0 : 6+label_offset})\n",
        "  dfsankey[\"increment\"] = dfsankey[\"increment\"].map({True : 'rgba(86,180,86, 0.7)', False: 'rgba(222,82,83, 0.7)'})\n",
        "  dfsankey = dfsankey.sort_values(by=['target'])\n",
        "  return dfsankey"
      ],
      "metadata": {
        "id": "UUdp7i0txWPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "names = [\"base\",\"bio-full\",\"med-reg-v0\",\"med-reg-v1\"]\n",
        "dfs_list = []\n",
        "for i in range(1,len(names)):\n",
        "  dfs_list.append(getSankeyDataFrame(names[i-1],names[i],df,6*i))\n",
        "dfs = pd.concat(dfs_list, axis=0)\n",
        "\n",
        "fig = go.Figure(data=[go.Sankey(\n",
        "    node = dict(\n",
        "      pad = 10,\n",
        "      thickness = 10,\n",
        "      line = dict(color = \"black\", width = 0.5),\n",
        "      label = [\"1st\",\"2nd\",\"3rd\",\"4th\",\"5th\",\"None\"]*2*len(dfs_list),\n",
        "      color = [\"#1F6FB3\",\"#4896C8\",\"#7EB8DA\",\"#B5D4E9\",\"#D9E8F5\",\"#F7FBFF\"]*2*len(dfs_list),#,\"#DCE2F0\",\"#AFAEDA\",\"#9C81C4\",\"#9856AB\",\"#833E75\",\"#59283A\"],\n",
        "    ),\n",
        "    link = dict(\n",
        "      source = dfs[\"source\"], # indices correspond to labels, eg A1, A2, A1, B1, ...\n",
        "      target = dfs[\"target\"],\n",
        "      value = dfs[\"value\"],\n",
        "      color = dfs[\"increment\"],\n",
        "      label = dfs[\"word\"]\n",
        "  ))])\n",
        "\n",
        "for x_coordinate, column_name in enumerate(names):\n",
        "  fig.add_annotation(\n",
        "          x=x_coordinate / (len(names) - 1),\n",
        "          y=1.1,\n",
        "          xref=\"paper\",\n",
        "          yref=\"paper\",\n",
        "          text=column_name,\n",
        "          showarrow=False,\n",
        "          font=dict(\n",
        "              size=12,\n",
        "              color=\"black\"\n",
        "              ),\n",
        "          align=\"center\",\n",
        "          )\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "GgJf3IFRo56B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Standard Scatter+Line plot for Paper"
      ],
      "metadata": {
        "id": "ac2jJ7VE96He"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dftrend = pd.read_csv(\"mlm_trend.csv\")"
      ],
      "metadata": {
        "id": "Zvilfic0EGZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the 28GB jump between BioBIT_M and BioBIT_L is an issue when plotting the MRR progression\n",
        "#convert pretraining size from int to str to make it categorical and add an axis break manually\n",
        "dftrend[\"total_pt_size\"]=[str(x) for x in dftrend[\"total_pt_size\"]]"
      ],
      "metadata": {
        "id": "pjCzb40YGTX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "font = {'size'   : 18}\n",
        "plt.rc('font', **font)\n",
        "\n",
        "f, ax = plt.subplots(figsize=(14, 10))\n",
        "ax.set_xlabel('Total pretraining size (GB)')\n",
        "ax.set_ylabel('MRR')\n",
        "f = sns.scatterplot(data=dftrend, x=\"total_pt_size\", y=\"mrr\", style=\"latest_pt_corpus_type\", s=180)\n",
        "#[ax.text(p[0], p[1], p[2], color='#2078B4', ha='left') for p in zip(dftrend[\"total_pt_size\"], dftrend[\"mrr\"]+0.0013,dftrend[\"model\"])]\n",
        "dfline = dftrend[((dftrend['model'] != \"BioBIT_XS\") & (dftrend['model'] != \"MedBIT\") &  (dftrend['model'] != \"MedBIT_R3+\"))]\n",
        "leg = plt.legend(title='Latest pretraining corpus\\n')\n",
        "leg._legend_box.align = \"left\"\n",
        "plt.plot(dfline[\"total_pt_size\"], dfline[\"mrr\"], color='orange', linewidth=2)\n",
        "plt.savefig('/content/trend.png')"
      ],
      "metadata": {
        "id": "KvPXwzIGGFSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test su CONTESTO\n",
        "\n",
        "This test focus on determine how the wideness and position of the context window around the masked word influences the predictions.\n",
        "\n",
        "We take into account a selection of biomedical texts with around 512 tokens long and we repeat the same process seen before but changing the size of the context window.\n",
        "\n",
        "Example:\n",
        "\n",
        "```\n",
        "\n",
        "ORIGINAL TEXT: \"(1) È difficile consigliare una prevenzione efficace. (2) Senza dubbio è importante non fumare e seguire una dieta povera di alcol. (3) Circa il 70% dei tumori del pancreas si sviluppa nella \\[MASK\\] dell'organo. (4) Nella maggior parte dei casi, il tumore ha origine nei dotti che trasportano gli enzimi della digestione. (5) Tale neoplasia prende il nome di adenocarcinoma duttale del pancreas.\"\n",
        "\n",
        "N.B.: (N) indicates the sentence index and is not included in the text.\n",
        "\n",
        "MASKED WORD: \"testa\"\n",
        "\n",
        "FIRST ITERATION INPUT ([3]): \"(3) Circa il 70% dei tumori del pancreas si sviluppa nella \\[MASK\\] dell'organo.\"\n",
        "\n",
        "SECOND ITERATION INPUT ([2,3,4]): \"(2) Senza dubbio è importante non fumare e seguire una dieta povera di alcol. (3) Circa il 70% dei tumori del pancreas si sviluppa nella \\[MASK\\] dell'organo. (4) Nella maggior parte dei casi, il tumore ha origine nei dotti che trasportano gli enzimi della digestione.\"\n",
        "\n",
        "THIRD ITERATION INPUT ([1,2,3,4,5]): \"(1) È difficile consigliare una prevenzione efficace. (2) Senza dubbio è importante non fumare e seguire una dieta povera di alcol. (3) Circa il 70% dei tumori del pancreas si sviluppa nella \\[MASK\\] dell'organo. (4) Nella maggior parte dei casi, il tumore ha origine nei dotti che trasportano gli enzimi della digestione. (5) Tale neoplasia prende il nome di adenocarcinoma duttale del pancreas.\"\n",
        "```"
      ],
      "metadata": {
        "id": "-o66DZfnOsM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = open(\"/content/mlm_context_window.json\", encoding=\"utf-8\")\n",
        "json_data = json.load(g)\n",
        "contexts = json_data[\"contexts\"]\n",
        "g.close()"
      ],
      "metadata": {
        "id": "kZqUF8O9WKZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# utility to create different versions of the input text varying in length\n",
        "def generate_input_sents(sents, ind_center, replacement=\"\"):\n",
        "  i = 0\n",
        "  sentences = []\n",
        "  if replacement!=\"\":\n",
        "    sents[ind_center] = replacement\n",
        "  while ind_center>i:\n",
        "    sentences.append(' '.join([sents[i] for i in range(ind_center-i,ind_center+i+1)]))\n",
        "    i+=1 \n",
        "  return(sentences)"
      ],
      "metadata": {
        "id": "2029U-MmI1w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_progression(checkpoint_name, sents, ind_center, mask):\n",
        "  m = generate_input_sents(sents, ind_center, replacement=mask)\n",
        "  r = evaluate_mlm(checkpoints[checkpoint_name], tokenizers[checkpoint_name], m, print_progression=False)\n",
        "  s = get_results(r, original_sentences, m, tokenizers[checkpoint_name], verbose=False)\n",
        "  return s"
      ],
      "metadata": {
        "id": "0umXcrFUaE_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Results"
      ],
      "metadata": {
        "id": "X2Lkitvmfp6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for context in [contexts[0]]:\n",
        "#for context in contexts: \n",
        "\n",
        "  original_text = context[\"original\"]\n",
        "  masks = context[\"masks\"]\n",
        "  sents = original_text.split(\"\\n\")\n",
        "  ind_center = math.floor(len(sents)/2)\n",
        "  original_sentences = generate_input_sents(sents, ind_center)\n",
        "\n",
        "  print(\"=============================\")\n",
        "  print(f\"* context: '{original_text}'\")\n",
        "  print(f\"\\n* length: {len(tokenizers['base'](original_text)['input_ids'])} tokens\")\n",
        "  print(f\"* num sentences: {len(sents)}\")\n",
        "  print(f\"* central sentence: '{sents[ind_center]}'\")\n",
        "  print(\"-----------------------------\\n\")\n",
        "\n",
        "  for mask in masks:\n",
        "    m = generate_input_sents(sents, ind_center, replacement=mask)\n",
        "    print(m[0])\n",
        "    print(f\"[MASK] = {get_masked_word(original_sentences, m)[0]}\\n\")\n",
        "    for k,v in checkpoints.items():\n",
        "      s = get_progression(k, sents, ind_center, mask)\n",
        "      print(f\" -{k}: {s['avg']:.2f}%, {s['scores']}\")\n",
        "    print(\"-----------------------------\\n\")"
      ],
      "metadata": {
        "id": "KKrfYE4qWHk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Psuedo Perplexity"
      ],
      "metadata": {
        "id": "_7FtqpFpqKoQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a paper called [Masked Language Model Scoring](https://arxiv.org/abs/1910.14659) that explores pseudo-perplexity from masked language models and shows that pseudo-perplexity, while not being theoretically well justified, still performs well for comparing \"naturalness\" of texts.\n",
        "\n",
        "Here we apply PPPL to all the sentences included in the MLM dataset for each model checkpoint."
      ],
      "metadata": {
        "id": "-jZBPSdCyp9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "def score(model, tokenizer, sentence):\n",
        "  \"\"\"\n",
        "  The function below calculates average probability of each token in the sentence given all the other tokens.\n",
        "  In masked language models, this does not amount to the total probability of the whole sentence (the conditional probabilities do not cancel each other out), but it is still a useful measure of a \"naturallness\" of a sentence.\n",
        "  \"\"\"\n",
        "  tensor_input = tokenizer.encode(sentence, return_tensors='pt')\n",
        "  repeat_input = tensor_input.repeat(tensor_input.size(-1)-2, 1)\n",
        "  mask = torch.ones(tensor_input.size(-1) - 1).diag(1)[:-2]\n",
        "  masked_input = repeat_input.masked_fill(mask == 1, tokenizer.mask_token_id)\n",
        "  labels = repeat_input.masked_fill( masked_input != tokenizer.mask_token_id, -100)\n",
        "  del tensor_input, repeat_input, mask\n",
        "  with torch.inference_mode():\n",
        "      loss = model(masked_input.to(device), labels=labels.to(device)).loss\n",
        "  del masked_input, labels\n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "  return np.exp(loss.item())"
      ],
      "metadata": {
        "id": "YoC3M0-trkdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pseudo_perplexity_total(model, tokenizer, sentences):\n",
        "  pppl = 0\n",
        "  skipped = 0\n",
        "  for i in tqdm(range(len(sentences))):\n",
        "    sentence = sentences[i]\n",
        "    if tokenizer.encode(sentence, return_tensors='pt').shape[1]>170: ###OOM Error in Colab if text is too long\n",
        "      skipped += 1\n",
        "      continue\n",
        "    pppl += score(model,tokenizer,sentence)\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "  return pppl/(len(sentences)-skipped)"
      ],
      "metadata": {
        "id": "d4Qof2v9uhok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_sentences = [sentence[\"original\"] for sentence in sentences]\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "for k,v in checkpoints.items():\n",
        "  model = AutoModelForMaskedLM.from_pretrained(v)\n",
        "  tokenizer=tokenizers[k]\n",
        "  pppl_total = 0\n",
        "  pppl_total = get_pseudo_perplexity_total(model, tokenizer, original_sentences)\n",
        "  print(f\"Model Name: {k}\")\n",
        "  print(f\"Average PPPL: {pppl_total}\")\n",
        "  del model, tokenizer"
      ],
      "metadata": {
        "id": "Ts4NwAixvN56"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}